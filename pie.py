import requests
import os
from typing import Optional, List
from requests.exceptions import RequestException
import json
from urllib.parse import quote


def _create_save_dir(save_dir: str) -> None:
    """
    è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºä¿å­˜ç›®å½•ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
    :param save_dir: æœ¬åœ°ä¿å­˜ç›®å½•è·¯å¾„
    """
    if not os.path.exists(save_dir):
        os.makedirs(save_dir, exist_ok=True)
        print(f"å·²åˆ›å»ºä¿å­˜ç›®å½•ï¼š{save_dir}")


def _download_media(media_url: str, save_path: str) -> bool:
    """
    è¾…åŠ©å‡½æ•°ï¼šä¸‹è½½å•ä¸ªåª’ä½“æ–‡ä»¶ï¼ˆå›¾ç‰‡/è§†é¢‘ï¼‰åˆ°æœ¬åœ°
    :param media_url: åª’ä½“æ–‡ä»¶çš„è¿œç¨‹URL
    :param save_path: æœ¬åœ°ä¿å­˜è·¯å¾„ï¼ˆå«æ–‡ä»¶åï¼‰
    :return: ä¸‹è½½æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    try:
        # å‘é€GETè¯·æ±‚è·å–åª’ä½“æµï¼ˆè®¾ç½®è¶…æ—¶é¿å…é•¿æœŸé˜»å¡ï¼‰
        response = requests.get(media_url, stream=True, timeout=15)
        response.raise_for_status()  # è‹¥çŠ¶æ€ç é200ï¼ŒæŠ›å‡ºHTTPé”™è¯¯

        # å†™å…¥æ–‡ä»¶ï¼ˆäºŒè¿›åˆ¶æ¨¡å¼ï¼Œé€‚ç”¨äºå›¾ç‰‡/è§†é¢‘ï¼‰
        with open(save_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=1024 * 1024):  # 1MBåˆ†å—ä¸‹è½½
                if chunk:
                    f.write(chunk)

        print(f"âœ… æˆåŠŸä¸‹è½½ï¼š{os.path.basename(save_path)}")
        return True

    except RequestException as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼ˆURL: {media_url}ï¼‰ï¼š{str(e)}")
        return False


def download_pixabay_images(
        api_key: str,
        q: str,
        save_dir: str = "./pixabay_images",
        per_page: int = 10,
        page: int = 1,
        image_type: str = "photo",
        orientation: str = "all"
) -> List[str]:
    """
    ä»Pixabay APIæœç´¢å¹¶ä¸‹è½½å›¾ç‰‡
    :param api_key: Pixabay APIå¯†é’¥ï¼ˆå¿…å¡«ï¼Œä»Pixabayè´¦å·è·å–ï¼‰
    :param q: æœç´¢å…³é”®è¯ï¼ˆå¦‚"yellow flowers"ï¼ŒURLç¼–ç ç”±å‡½æ•°è‡ªåŠ¨å¤„ç†ï¼‰
    :param save_dir: æœ¬åœ°ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ï¼š./pixabay_imagesï¼‰
    :param per_page: æ¯é¡µä¸‹è½½æ•°é‡ï¼ˆ3-200ï¼Œé»˜è®¤10ï¼Œéµå¾ªAPIé™åˆ¶ï¼‰
    :param page: åˆ†é¡µé¡µç ï¼ˆé»˜è®¤1ï¼Œç”¨äºè·å–å¤šé¡µç»“æœï¼‰
    :param image_type: å›¾ç‰‡ç±»å‹ï¼ˆall/photo/illustration/vectorï¼Œé»˜è®¤photoï¼‰
    :param orientation: å›¾ç‰‡æ–¹å‘ï¼ˆall/horizontal/verticalï¼Œé»˜è®¤allï¼‰
    :return: æˆåŠŸä¸‹è½½çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    # 1. åˆå§‹åŒ–é…ç½®
    _create_save_dir(save_dir)
    success_paths = []
    api_url = "https://pixabay.com/api/"  # å›¾ç‰‡APIç«¯ç‚¹

    # 2. æ„é€ APIè¯·æ±‚å‚æ•°ï¼ˆä¸¥æ ¼éµå¾ªPixabay APIæ–‡æ¡£ï¼‰
    params = {
        "key": api_key,
        "q": q,
        "image_type": image_type,
        "orientation": orientation,
        "per_page": per_page,
        "page": page,
        "pretty": "false"  # ç”Ÿäº§ç¯å¢ƒç¦ç”¨ç¼©è¿›ï¼Œæé«˜æ•ˆç‡
    }

    try:
        # 3. å‘é€APIè¯·æ±‚ï¼ˆè·å–å›¾ç‰‡åˆ—è¡¨ï¼‰
        response = requests.get(api_url, params=params, timeout=10)
        response.raise_for_status()  # æ•è·HTTPé”™è¯¯ï¼ˆå¦‚429é€Ÿç‡é™åˆ¶ã€400å‚æ•°é”™è¯¯ï¼‰
        api_data = response.json()

        # 4. è§£æAPIå“åº”ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰ç»“æœï¼‰
        total_hits = api_data.get("totalHits", 0)
        if total_hits == 0:
            print(f"âš ï¸ æœªæ‰¾åˆ°å…³é”®è¯ã€Œ{q}ã€çš„å›¾ç‰‡ç»“æœ")
            return success_paths

        print(f"ğŸ“¥ æ‰¾åˆ°{total_hits}å¼ å›¾ç‰‡ï¼Œå¼€å§‹ä¸‹è½½ç¬¬{page}é¡µï¼ˆå…±{per_page}å¼ ï¼‰...")

        # 5. éå†å›¾ç‰‡ç»“æœï¼Œæå–URLå¹¶ä¸‹è½½
        for idx, hit in enumerate(api_data["hits"], 1):
            # æå–å›¾ç‰‡URLï¼ˆwebformatURLï¼š640pxä¸­ç­‰å°ºå¯¸ï¼Œ24å°æ—¶æœ‰æ•ˆï¼Œç¬¦åˆAPIè§„èŒƒï¼‰
            img_url = hit.get("webformatURL")
            if not img_url:
                print(f"âš ï¸ è·³è¿‡ç¬¬{idx}å¼ å›¾ç‰‡ï¼šæœªè·å–åˆ°æœ‰æ•ˆURL")
                continue

            # ç”Ÿæˆæœ¬åœ°ä¿å­˜è·¯å¾„ï¼ˆé¿å…æ–‡ä»¶åé‡å¤ï¼ŒåŠ åºå·ï¼‰
            img_filename = f"pixabay_img_{hit['id']}_{idx}.jpg"  # ç”¨å›¾ç‰‡IDç¡®ä¿å”¯ä¸€æ€§
            save_path = os.path.join(save_dir, img_filename)

            # ä¸‹è½½å›¾ç‰‡å¹¶è®°å½•æˆåŠŸè·¯å¾„
            if _download_media(img_url, save_path):
                success_paths.append(save_path)

    except RequestException as e:
        print(f"âŒ APIè¯·æ±‚å¤±è´¥ï¼š{str(e)}")
        # ç‰¹æ®Šæç¤ºï¼šé€Ÿç‡é™åˆ¶ï¼ˆ429é”™è¯¯ï¼‰
        if response.status_code == 429:
            reset_time = response.headers.get("X-RateLimit-Reset", "æœªçŸ¥")
            print(f"âš ï¸ å·²è¶…è¿‡APIé€Ÿç‡é™åˆ¶ï¼ˆ100æ¬¡/60ç§’ï¼‰ï¼Œè¯·{reset_time}ç§’åé‡è¯•")

    return success_paths


def download_pixabay_videos(
    api_key: str,
    q: str,
    save_dir: str = "./pixabay_videos",
    per_page: int = 5,
    page: int = 1,
    video_type: str = "film",
    video_size: str = "medium"
) -> List[str]:
    """
    ä»Pixabay APIæœç´¢å¹¶ä¸‹è½½è§†é¢‘
    :param api_key: Pixabay APIå¯†é’¥ï¼ˆå¿…å¡«ï¼‰
    :param q: æœç´¢å…³é”®è¯ï¼ˆå¦‚"ocean wave"ï¼‰
    :param save_dir: æœ¬åœ°ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ï¼š./pixabay_videosï¼‰
    :param per_page: æ¯é¡µä¸‹è½½æ•°é‡ï¼ˆ3-200ï¼Œé»˜è®¤5ï¼Œè§†é¢‘æ–‡ä»¶è¾ƒå¤§å»ºè®®å°‘é€‰ï¼‰
    :param page: åˆ†é¡µé¡µç ï¼ˆé»˜è®¤1ï¼‰
    :param video_type: è§†é¢‘ç±»å‹ï¼ˆall/film/animationï¼Œé»˜è®¤filmï¼‰
    :param video_size: è§†é¢‘å°ºå¯¸ï¼ˆlarge/medium/small/tinyï¼Œé»˜è®¤mediumï¼ŒAPIæ–‡æ¡£æ¨èï¼‰
    :return: æˆåŠŸä¸‹è½½çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    # 1. åˆå§‹åŒ–é…ç½®
    _create_save_dir(save_dir)
    success_paths = []
    api_url = "https://pixabay.com/api/videos/"  # è§†é¢‘APIç«¯ç‚¹
    valid_sizes = ["large", "medium", "small", "tiny"]

    # æ£€æŸ¥è§†é¢‘å°ºå¯¸æ˜¯å¦åˆæ³•
    if video_size not in valid_sizes:
        print(f"âš ï¸ æ— æ•ˆè§†é¢‘å°ºå¯¸ã€Œ{video_size}ã€ï¼Œè‡ªåŠ¨ä½¿ç”¨é»˜è®¤å€¼ã€Œmediumã€")
        video_size = "medium"

    # 2. æ„é€ APIè¯·æ±‚å‚æ•°
    params = {
        "key": api_key,
        "q": q,
        "video_type": video_type,
        "per_page": per_page,
        "page": page,
        "pretty": "false"
    }

    try:
        # 3. å‘é€APIè¯·æ±‚
        response = requests.get(api_url, params=params, timeout=15)
        # å…³é”®ä¼˜åŒ–ï¼šæ‰“å°400é”™è¯¯çš„å…·ä½“å“åº”å†…å®¹ï¼ˆAPIä¼šæ˜ç¡®è¯´æ˜é”™è¯¯åŸå› ï¼‰
        if response.status_code == 400:
            print(f"âŒ è§†é¢‘APIå‚æ•°é”™è¯¯ï¼Œè¯¦æƒ…ï¼š{response.text}")  # é‡ç‚¹ï¼çœ‹è¿™é‡Œçš„é”™è¯¯æç¤º
            return success_paths

        response.raise_for_status()  # æ•è·å…¶ä»–HTTPé”™è¯¯ï¼ˆå¦‚401æƒé™ã€429é€Ÿç‡ï¼‰
        api_data = response.json()

        # 4. è§£æå“åº”
        total_hits = api_data.get("totalHits", 0)
        if total_hits == 0:
            print(f"âš ï¸ æœªæ‰¾åˆ°å…³é”®è¯ã€Œ{q}ã€çš„è§†é¢‘ç»“æœ")
            return success_paths

        print(f"ğŸ“¥ æ‰¾åˆ°{total_hits}ä¸ªè§†é¢‘ï¼Œå¼€å§‹ä¸‹è½½ç¬¬{page}é¡µï¼ˆå…±{per_page}ä¸ªï¼Œå°ºå¯¸ï¼š{video_size}ï¼‰...")

        # 5. éå†è§†é¢‘ç»“æœï¼Œæå–å¯¹åº”å°ºå¯¸çš„URLå¹¶ä¸‹è½½
        for idx, hit in enumerate(api_data["hits"], 1):
            # æå–æŒ‡å®šå°ºå¯¸çš„è§†é¢‘URLï¼ˆè§†é¢‘APIè¿”å›å¤šå°ºå¯¸å­—å…¸ï¼‰
            video_info = hit.get("videos", {}).get(video_size)
            if not video_info or not video_info.get("url"):
                print(f"âš ï¸ è·³è¿‡ç¬¬{idx}ä¸ªè§†é¢‘ï¼šæœªè·å–åˆ°ã€Œ{video_size}ã€å°ºå¯¸çš„URL")
                continue

            video_url = video_info["url"]

            # ç”Ÿæˆæœ¬åœ°ä¿å­˜è·¯å¾„ï¼ˆç”¨è§†é¢‘IDç¡®ä¿å”¯ä¸€æ€§ï¼‰
            video_filename = f"pixabay_video_{hit['id']}_{idx}.mp4"
            save_path = os.path.join(save_dir, video_filename)

            # ä¸‹è½½è§†é¢‘å¹¶è®°å½•æˆåŠŸè·¯å¾„
            if _download_media(video_url, save_path):
                success_paths.append(save_path)

    except RequestException as e:
        print(f"âŒ è§†é¢‘APIè¯·æ±‚å¤±è´¥ï¼š{str(e)}")
        # é€Ÿç‡é™åˆ¶æç¤º
        if 'response' in locals() and response.status_code == 429:
            reset_time = response.headers.get("X-RateLimit-Reset", "æœªçŸ¥")
            print(f"âš ï¸ å·²è¶…è¿‡APIé€Ÿç‡é™åˆ¶ï¼Œè«‹{reset_time}ç§’åé‡è¯•")

    return success_paths


def search_pexels_videos(
    api_key: str,
    query: str,
    per_page: int = 5,
    page: int = 1,
    orientation: str = "landscape"
) -> List[dict]:
    """
    ä»Pexelsæœç´¢è§†é¢‘ç´ æ
    :param api_key: Pexels APIå¯†é’¥
    :param query: æœç´¢å…³é”®è¯
    :param per_page: æ¯é¡µæ•°é‡ï¼ˆé»˜è®¤5ï¼‰
    :param page: é¡µç ï¼ˆé»˜è®¤1ï¼‰
    :param orientation: è§†é¢‘æ–¹å‘ï¼ˆlandscape, portrait, squareï¼‰
    :return: è§†é¢‘ä¿¡æ¯åˆ—è¡¨
    """
    url = "https://api.pexels.com/videos/search"
    headers = {
        "Authorization": api_key
    }
    params = {
        "query": query,
        "per_page": per_page,
        "page": page,
        "orientation": orientation
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        return data.get("videos", [])
    except Exception as e:
        print(f"âŒ Pexelsè§†é¢‘æœç´¢å¤±è´¥ï¼š{str(e)}")
        return []


def download_pexels_video(video_data: dict, save_dir: str = "./pexels_videos") -> Optional[str]:
    """
    ä¸‹è½½Pexelsè§†é¢‘
    :param video_data: Pexelsè§†é¢‘æ•°æ®
    :param save_dir: ä¿å­˜ç›®å½•
    :return: ä¿å­˜è·¯å¾„æˆ–None
    """
    _create_save_dir(save_dir)
    
    # è·å–è§†é¢‘é“¾æ¥ï¼ˆé€‰æ‹©æœ€é«˜è´¨é‡ï¼‰
    video_files = video_data.get("video_files", [])
    if not video_files:
        print("âš ï¸ è§†é¢‘æ•°æ®ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return None
    
    # é€‰æ‹©ç¬¬ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯æœ€é«˜è´¨é‡ï¼‰
    video_url = video_files[0].get("link")
    if not video_url:
        print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘é“¾æ¥")
        return None
    
    # ç”Ÿæˆæ–‡ä»¶å
    video_id = video_data.get("id", "unknown")
    save_path = os.path.join(save_dir, f"pexels_video_{video_id}.mp4")
    
    # ä¸‹è½½è§†é¢‘
    if _download_media(video_url, save_path):
        return save_path
    return None


def search_unsplash_images(
    api_key: str,
    query: str,
    per_page: int = 10,
    page: int = 1
) -> List[dict]:
    """
    ä»Unsplashæœç´¢å›¾ç‰‡ç´ æ
    :param api_key: Unsplash APIå¯†é’¥
    :param query: æœç´¢å…³é”®è¯
    :param per_page: æ¯é¡µæ•°é‡
    :param page: é¡µç 
    :return: å›¾ç‰‡ä¿¡æ¯åˆ—è¡¨
    """
    url = "https://api.unsplash.com/search/photos"
    headers = {
        "Authorization": f"Client-ID {api_key}"
    }
    params = {
        "query": query,
        "per_page": per_page,
        "page": page
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        return data.get("results", [])
    except Exception as e:
        print(f"âŒ Unsplashå›¾ç‰‡æœç´¢å¤±è´¥ï¼š{str(e)}")
        return []


def download_unsplash_image(image_data: dict, save_dir: str = "./unsplash_images") -> Optional[str]:
    """
    ä¸‹è½½Unsplashå›¾ç‰‡
    :param image_data: Unsplashå›¾ç‰‡æ•°æ®
    :param save_dir: ä¿å­˜ç›®å½•
    :return: ä¿å­˜è·¯å¾„æˆ–None
    """
    _create_save_dir(save_dir)
    
    # è·å–å›¾ç‰‡é“¾æ¥ï¼ˆé€‰æ‹©å…¨å°ºå¯¸ï¼‰
    image_url = image_data.get("urls", {}).get("full")
    if not image_url:
        image_url = image_data.get("urls", {}).get("regular")
    
    if not image_url:
        print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾ç‰‡é“¾æ¥")
        return None
    
    # ç”Ÿæˆæ–‡ä»¶å
    image_id = image_data.get("id", "unknown")
    save_path = os.path.join(save_dir, f"unsplash_image_{image_id}.jpg")
    
    # ä¸‹è½½å›¾ç‰‡
    if _download_media(image_url, save_path):
        return save_path
    return None


def search_youtube_videos(
    api_key: str,
    query: str,
    max_results: int = 5
) -> List[dict]:
    """
    ä»YouTubeæœç´¢è§†é¢‘ï¼ˆä»…è·å–ä¿¡æ¯ï¼Œä¸ä¸‹è½½ï¼‰
    :param api_key: YouTube Data APIå¯†é’¥
    :param query: æœç´¢å…³é”®è¯
    :param max_results: æœ€å¤§ç»“æœæ•°
    :return: è§†é¢‘ä¿¡æ¯åˆ—è¡¨
    """
    url = "https://www.googleapis.com/youtube/v3/search"
    params = {
        "key": api_key,
        "q": query,
        "part": "snippet",
        "type": "video",
        "maxResults": max_results
    }
    
    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        return data.get("items", [])
    except Exception as e:
        print(f"âŒ YouTubeè§†é¢‘æœç´¢å¤±è´¥ï¼š{str(e)}")
        return []


# ------------------- æµ‹è¯•ç¤ºä¾‹ -------------------
if __name__ == "__main__":
    # 1. æ›¿æ¢ä¸ºä½ çš„Pixabay APIå¯†é’¥ï¼ˆä»https://pixabay.com/api/docs/è·å–ï¼‰
    PIXABAY_API_KEY = "52039769-cde28ab07929ebcb29572fc53"  # æ–‡æ¡£ç¤ºä¾‹å¯†é’¥ï¼Œå»ºè®®ç”¨è‡ªå·±çš„

    # 2. æµ‹è¯•ä¸‹è½½å›¾ç‰‡ï¼ˆå…³é”®è¯ï¼šé»„è‰²èŠ±æœµï¼Œä¿å­˜åˆ°./pixabay_imagesï¼‰
    print("=" * 50)
    print("å¼€å§‹æµ‹è¯•ä¸‹è½½å›¾ç‰‡...")
    # image_paths = download_pixabay_images(
    #     api_key=PIXABAY_API_KEY,
    #     q="yellow flowers",  # æœç´¢å…³é”®è¯
    #     per_page=3,  # ä¸‹è½½3å¼ 
    #     image_type="photo"  # åªä¸‹è½½ç…§ç‰‡
    # )
    # print(f"å›¾ç‰‡ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸè·¯å¾„ï¼š{image_paths}")

    # 3. æµ‹è¯•ä¸‹è½½è§†é¢‘ï¼ˆå…³é”®è¯ï¼šæµ·æ´‹æ³¢æµªï¼Œä¿å­˜åˆ°./pixabay_videosï¼‰
    print("\n" + "=" * 50)
    print("å¼€å§‹æµ‹è¯•ä¸‹è½½è§†é¢‘...")
    video_paths = download_pixabay_videos(
        api_key=PIXABAY_API_KEY,
        q="ocean wave",  # æœç´¢å…³é”®è¯
        per_page=3,  # ä¸‹è½½2ä¸ªï¼ˆè§†é¢‘æ–‡ä»¶è¾ƒå¤§ï¼‰
        video_size="small"  # ä¸‹è½½å°å°ºå¯¸ï¼ˆé€Ÿåº¦å¿«ï¼‰
    )
    print(f"è§†é¢‘ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸè·¯å¾„ï¼š{video_paths}")