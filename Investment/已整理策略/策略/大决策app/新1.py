import datetime
from pprint import pprint

import requests

from Investment.THS.AutoTrade.utils.format_data import determine_market
# from Investment.THS.AutoTrade.utils import logger
from Investment.THS.AutoTrade.utils.logger import setup_logger

logger  = setup_logger(__name__)

def get_portfolio_industry_theme():
    """è·å–ç»„åˆè¡Œä¸šä¸»é¢˜æ•°æ®ï¼ˆGETè¯·æ±‚ï¼‰"""
    # è¯·æ±‚URL
    url = "https://nkmapiv3.aniu.tv/nkm-api/Rest2/api/INKBPortfolio/getPortfolioIndustryThemeV2"

    # URLå‚æ•°
    params = {
        "aniu_uid": "3a51f1c06372435cbb79e41609285c1a",
        "get_type": "0",
        "pfId": "132008",
        "pfid": "132008",
        "user_level": "1",
        "channelid": "700015",
        "clienttype": "3",
        "clientid": "first_install_android_id",
        "devid": "800009",
        "time": "20250714130243",
        "version": "6.9.63",
        "platform": "app_anzt_anzt",
        "platForm": "app_anzt_anzt",
        "sign": "d27c8505dccf72ab39afe62effadefd3"
    }

    # è¯·æ±‚å¤´
    headers = {
        "Host": "nkmapiv3.aniu.tv",
        "Connection": "Keep-Alive",
        "Accept-Encoding": "gzip",
        "User-Agent": "okhttp/4.2.0"
    }

    try:
        # å‘é€GETè¯·æ±‚
        response = requests.get(
            url,
            params=params,
            headers=headers,
            verify=True
        )
        response.raise_for_status()
        response_json = response.json()
        print(response_json)
        return response_json

    except requests.RequestException as e:
        # logger.error(f"è¯·æ±‚å‡ºé”™ (ID: {portfolio_id}): {e}")
        return []

    # today_trades = []
    # noteContent = response_json.get('noteContent', [])

    # for item in noteContent:
    #     createAt = item.get('createAt', '') or ''
    #     raw_content = item.get('content', '') or ''
    #     relocateList = item.get('relocateList', [])
    #
    #     # æå–è°ƒä»“ç†ç”±å’Œæ ‡çš„åç§°
    #     extracted_name, clean_reason = extract_stock_analysis(raw_content)
    #
    #     for infos in relocateList:
    #         code = str(infos.get('code', '')).zfill(6)
    #         name = (infos.get('name') or '').replace('\n', '').strip() or 'æ— '
    #
    #         if '***' in name:
    #             name = extracted_name
    #
    #         current_ratio = infos.get('currentRatio', 0)
    #         new_ratio = infos.get('newRatio', 0)
    #         operation = 'ä¹°å…¥' if new_ratio > current_ratio else 'å–å‡º'
    #         market = determine_market(code)
    #
    #         history_post = {
    #             'ç»„åˆåç§°': id_to_name.get(str(portfolio_id), 'æœªçŸ¥ç»„åˆ'),
    #             'æ“ä½œ': operation,
    #             'æ ‡çš„åç§°': name,
    #             'ä»£ç ': str(code).zfill(6),
    #             'æœ€æ–°ä»·': infos.get('finalPrice'),
    #             'æ–°æ¯”ä¾‹%': round(new_ratio * 100, 2),
    #             'å¸‚åœº': market,
    #             'æ—¶é—´': createAt,
    #             'è°ƒä»“ç†ç”±': clean_reason
    #         }
    #
    #         # åˆ¤æ–­æ˜¯å¦æ˜¯ä»Šæ—¥æ•°æ®
    #         today = datetime.datetime.now().strftime('%Y-%m-%d')
    #         if today == createAt.split()[0]:
    #             today_trades.append(history_post)
    #
    # return today_trades

from bs4 import BeautifulSoup
import re
import pandas as pd


def extract_stock_analysis(html_content):
    soup = BeautifulSoup(html_content, 'html.parser')

    # æå–ç»„åˆå & è‚¡ç¥¨å & ä»£ç 
    title_span = soup.find('span', style=re.compile(r'color:\s*rgb$'))
    if not title_span:
        return None

    combination_name_match = re.search(r'ã€(.+?)ã€‘', title_span.text)
    combination_name = combination_name_match.group(1) if combination_name_match else 'æœªçŸ¥ç»„åˆ'

    stock_link = title_span.find('a', href=re.compile(r'productdetails\?code='))
    if not stock_link:
        return None

    stock_code = stock_link.get_text().strip()
    stock_name = stock_link.find_next('a').get_text().strip() if stock_link.find_next('a') else 'æœªçŸ¥'

    # æå–å‚è€ƒä¿¡æ¯
    def get_value_by_label(label_text):
        label_tag = soup.find(lambda tag: tag.name == 'span' and label_text in tag.text)
        if label_tag:
            return label_tag.text.replace(label_text, '').strip().replace("ï¼š", "").strip()
        return 'æ— '

    buy_price = get_value_by_label('å‚è€ƒä¹°å…¥ä»·æ ¼')
    position = get_value_by_label('å‚è€ƒä»“ä½')
    target_price = get_value_by_label('å‚è€ƒç›®æ ‡ä»·ä½')
    stop_loss = get_value_by_label('å‚è€ƒæ­¢æŸä»·ä½')

    # æå–å…¬å¸ä¸šåŠ¡ä»‹ç»ï¼ˆç¬¬ä¸€ä¸ª p æ®µè½ï¼‰
    business_intro = ''
    for p in soup.find_all('p'):
        text = p.get_text().strip()
        if len(text) > 50:
            business_intro = text
            break

    # æå–æŠ€æœ¯é¢åˆ†æ
    technical_analysis = ''
    tech_section = soup.find(lambda tag: tag.name == 'p' and 'æŠ€æœ¯é¢' in tag.text)
    if tech_section:
        next_p = tech_section.find_next('p')
        if next_p:
            technical_analysis = next_p.get_text().strip()

    # æå–é£é™©æç¤º
    risk_warnings = []
    risk_section = soup.find(lambda tag: tag.name == 'p' and 'é£é™©æç¤º' in tag.text)
    if risk_section:
        for li in risk_section.find_next_siblings('p'):
            txt = li.get_text().strip()
            if len(txt) > 5:
                risk_warnings.append(txt)
                if len(risk_warnings) >= 4:
                    break

    result = {
        'ç»„åˆåç§°': combination_name,
        'è‚¡ç¥¨ä»£ç ': stock_code,
        'è‚¡ç¥¨åç§°': stock_name,
        'ä¹°å…¥ä»·æ ¼åŒºé—´': buy_price,
        'å»ºè®®ä»“ä½': position,
        'ç›®æ ‡ä»·åŒºé—´': target_price,
        'æ­¢æŸä»·åŒºé—´': stop_loss,
        'å…¬å¸ä¸šåŠ¡ä»‹ç»': business_intro,
        'æŠ€æœ¯é¢åˆ†æ': technical_analysis,
        'é£é™©æç¤º': '; '.join(risk_warnings),
    }

    return result


# ç¤ºä¾‹ä½¿ç”¨
if __name__ == '__main__':
#     html_content = '''<p style="text-indent: 2em;"><span style="color: rgb(255, 0, 0);">ã€æœ±é›€15å·ã€‘ <a href='qcyzt://productdetails?code=sh603082'>sh603082</a> <a href='qcyzt://productdetails?code=sh603082'>åŒ—è‡ªç§‘æŠ€</a></span></p>
# <p></p><p style="text-indent: 2em;"><span style="color: rgb(255, 0, 0);">å‚è€ƒä¹°å…¥ä»·æ ¼ï¼š38.60-38.80</span></p>
# <p></p><p style="text-indent: 2em;"><span style="color: rgb(255, 0, 0);">å‚è€ƒä»“ä½ï¼š10%</span></p>
# <p></p><p style="text-indent: 2em;"><span style="color: rgb(255, 0, 0);">å‚è€ƒç›®æ ‡ä»·ä½ï¼š41.00-42.00</span></p>
# <p></p><p style="text-indent: 2em;"><span style="color: rgb(255, 0, 0);">å‚è€ƒæ­¢æŸä»·ä½ï¼š35.80-35.9</span></p>
# <p style="text-indent: 2em;">å…¬å¸ä¸»è¦ä»äº‹æ™ºèƒ½ç‰©æµç³»ç»Ÿå’Œè£…å¤‡çš„ç ”å‘...</p>
# <p style="text-indent: 2em;">é£é™©æç¤ºï¼šäº§å“åŠæœåŠ¡é”€å”®ä¸åŠé¢„æœŸï¼Œå¸‚åœºæ³¢åŠ¨è¶…é¢„æœŸ</p>
# <p style="text-indent: 2em;">æ¥æºï¼š2024å¹´å¹´æŠ¥</p>
# <p style="text-indent: 2em;">æŠ€æœ¯é¢ï¼šèµ°åŠ¿ä¸Šä¸Šï¼Œè‚¡ä»·è¿‘æœŸå›è°ƒ...</p>'''
    html_content = get_portfolio_industry_theme()
    pprint(html_content)
    analysis = extract_stock_analysis(html_content)
    if analysis:
        df = pd.DataFrame([analysis])
        print(df.to_string(index=False))
        # å¯é€‰ä¿å­˜åˆ° Excel æˆ– CSV
        # df.to_excel('stock_analysis.xlsx', index=False)


# async def process_stock_operations():
#     all_today_trades = []
#     for portfolio_id in all_ids:
#         trades = fetch_and_extract_data(portfolio_id)
#         all_today_trades.extend(trades)
#
#     # æŒ‰æ—¶é—´å€’åºæ’åº
#     all_today_trades.sort(key=lambda x: x['æ—¶é—´'], reverse=True)
#
#     # è½¬æ¢ä¸º DataFrame
#     df_today = pd.DataFrame(all_today_trades)
#
#     if not df_today.empty:
#         df_today['æ—¶é—´'] = df_today['æ—¶é—´'].apply(normalize_time)
#         df_today = df_today.reset_index(drop=True).set_index(df_today.index + 1)
#     else:
#         logger.info("âš ï¸ ä»Šæ—¥æ— äº¤æ˜“æ•°æ®")
#         return False
#
#     # è¿‡æ»¤æ‰éæ²ªæ·±Aè‚¡çš„æ•°æ®
#     df_today = df_today[df_today['å¸‚åœº'] == 'æ²ªæ·±Aè‚¡']
#
#     # è¯»å–å†å²è®°å½•
#     history_df_file = Combination_portfolio_today_file
#     expected_columns = ['ç»„åˆåç§°', 'æ“ä½œ', 'æ ‡çš„åç§°', 'ä»£ç ', 'æœ€æ–°ä»·', 'æ–°æ¯”ä¾‹%', 'å¸‚åœº', 'æ—¶é—´', 'è°ƒä»“ç†ç”±']
#     try:
#         df_history = read_portfolio_record_history(history_df_file)
#     except (FileNotFoundError, pd.errors.EmptyDataError):
#         df_history = pd.DataFrame(columns=expected_columns)
#         save_to_excel(df_history, history_df_file, index=False)
#
#     # æ ¼å¼æ ‡å‡†åŒ–
#     df_today = standardize_dataframe(df_today)
#     df_history = standardize_dataframe(df_history)
#
#     # è·å–æ–°å¢æ•°æ®
#     new_data = get_new_records(df_today, df_history)
#
#     if not new_data.empty:
#         # ä¿å­˜åˆ°æ–‡ä»¶
#         today_str = normalize_time(datetime.date.today().strftime('%Y-%m-%d'))
#         save_to_excel(new_data, history_df_file, sheet_name=today_str, index=False)
#
#         # å‘é€é€šçŸ¥ï¼ˆå»æ‰â€œè°ƒä»“ç†ç”±â€åˆ—ï¼‰
#         new_data_without_reason = new_data.drop(columns=['è°ƒä»“ç†ç”±'], errors='ignore')
#         send_notification(f"ğŸ“ˆ æ–°å¢äº¤æ˜“ {len(new_data)} æ¡ï¼š\n{new_data_without_reason.to_string(index=False)}")
#
#         return True
#     else:
#         logger.info("--------------- æ— æ–°å¢äº¤æ˜“æ•°æ® ----------------")
#         return False

if __name__ == '__main__':
    asyncio.run(process_stock_operations())
