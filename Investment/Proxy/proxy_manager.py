import os
import pandas as pd
from datetime import datetime
import logging
from typing import List, Optional
import sys
import importlib

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# åŠ¨æ€å¯¼å…¥ä¸¤ä¸ªä»£ç†çˆ¬è™«æ¨¡å—
try:
    import free_proxy
    import proxynova
    from proxy_utils import decode_js_ip, is_valid_ip, verify_proxy_curl_style
except ImportError as e:
    logging.error(f"å¯¼å…¥ä»£ç†æ¨¡å—å¤±è´¥: {e}")
    raise

class ProxyManager:
    """ä»£ç†ç®¡ç†å™¨ï¼Œç”¨äºæ•´åˆå¤šä¸ªä»£ç†æºå¹¶æä¾›ç»Ÿä¸€æ¥å£"""
    
    def __init__(self, proxy_data_dir: str = "./proxy_data"):
        """
        åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨
        
        Args:
            proxy_data_dir: ä»£ç†æ•°æ®ä¿å­˜ç›®å½•
        """
        self.proxy_data_dir = proxy_data_dir
        self.sources = ["free_proxy", "proxynova"]
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        if not os.path.exists(self.proxy_data_dir):
            os.makedirs(self.proxy_data_dir)
            
        # åˆå§‹åŒ–æ—¥å¿—
        self._init_logger()
        
    def _init_logger(self):
        """åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ"""
        log_format = "%(asctime)s - %(levelname)s - %(module)s:%(funcName)s - %(message)s"
        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler(os.path.join(self.proxy_data_dir, "proxy_manager.log"), encoding="utf-8")
            ]
        )
        
    def get_proxies_from_source(self, source: str, max_workers: int = 10, verify_timeout: float = 5.0) -> pd.DataFrame:
        """
        ä»æŒ‡å®šæºè·å–ä»£ç†
        
        Args:
            source: ä»£ç†æºåç§° ("free_proxy" æˆ– "proxynova")
            max_workers: éªŒè¯ä»£ç†çš„æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
            verify_timeout: éªŒè¯è¶…æ—¶æ—¶é—´
            
        Returns:
            pd.DataFrame: ä»£ç†æ•°æ®
        """
        try:
            if source == "free_proxy":
                # ä»free-proxy-list.netè·å–ä»£ç†
                df = free_proxy.crawl_free_proxies(
                    target_url="https://free-proxy-list.net",
                    save_dir=self.proxy_data_dir,
                    verify_proxies=True,
                    max_workers=max_workers,
                    verify_timeout=verify_timeout
                )
                return df
            elif source == "proxynova":
                # ä»proxynovaè·å–ä»£ç†
                df = proxynova.crawl_proxies(
                    # url="https://www.proxynova.com/proxy-server-list/",
                    url="https://www.proxynova.com/proxy-server-list/country-cn/",
                    save_dir=self.proxy_data_dir,
                    verify_proxies=True,
                    max_workers=max_workers,
                    verify_timeout=verify_timeout
                )
                return df
            else:
                logging.warning(f"æœªçŸ¥çš„ä»£ç†æº: {source}")
                return pd.DataFrame()
        except Exception as e:
            logging.error(f"ä» {source} è·å–ä»£ç†å¤±è´¥: {e}")
            return pd.DataFrame()
            
    def get_proxies(self, max_workers: int = 10, verify_timeout: float = 5.0, 
                   fallback: bool = True) -> pd.DataFrame:
        """
        è·å–ä»£ç†ï¼Œæ”¯æŒè‡ªåŠ¨åˆ‡æ¢æº
        
        Args:
            max_workers: éªŒè¯ä»£ç†çš„æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
            verify_timeout: éªŒè¯è¶…æ—¶æ—¶é—´
            fallback: æ˜¯å¦å¯ç”¨å¤‡ç”¨æºï¼ˆä¸€ä¸ªæºå¤±è´¥æ—¶åˆ‡æ¢åˆ°å¦ä¸€ä¸ªï¼‰
            
        Returns:
            pd.DataFrame: ä»£ç†æ•°æ®
        """
        logging.info("ğŸ”„ å¼€å§‹è·å–ä»£ç†æ•°æ®...")
        
        # å°è¯•ä»ä¸»æºè·å–
        primary_source = self.sources[0]
        logging.info(f"ğŸ“¡ å°è¯•ä»ä¸»æº {primary_source} è·å–ä»£ç†...")
        proxies_df = self.get_proxies_from_source(
            source=primary_source, 
            max_workers=max_workers, 
            verify_timeout=verify_timeout
        )
        
        # å¦‚æœä¸»æºå¤±è´¥ä¸”å¯ç”¨äº†å¤‡ç”¨æºï¼Œåˆ™å°è¯•å¤‡ç”¨æº
        if fallback and (proxies_df is None or proxies_df.empty):
            logging.warning(f"ä¸»æº {primary_source} è·å–ä»£ç†å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æº...")
            for source in self.sources[1:]:
                logging.info(f"ğŸ“¡ å°è¯•ä»å¤‡ç”¨æº {source} è·å–ä»£ç†...")
                proxies_df = self.get_proxies_from_source(
                    source=source, 
                    max_workers=max_workers, 
                    verify_timeout=verify_timeout
                )
                if proxies_df is not None and not proxies_df.empty:
                    logging.info(f"âœ… æˆåŠŸä»å¤‡ç”¨æº {source} è·å–åˆ° {len(proxies_df)} ä¸ªä»£ç†")
                    break
                    
        # å¦‚æœæ‰€æœ‰æºéƒ½å¤±è´¥
        if proxies_df is None or proxies_df.empty:
            logging.error("âŒ æ‰€æœ‰ä»£ç†æºéƒ½æœªèƒ½è·å–åˆ°æœ‰æ•ˆä»£ç†")
            return pd.DataFrame()
            
        logging.info(f"âœ… æˆåŠŸè·å–åˆ° {len(proxies_df)} ä¸ªæœ‰æ•ˆä»£ç†")
        
        # ä¿å­˜åˆå¹¶åçš„ä»£ç†æ•°æ®
        today_date = datetime.now().strftime("%Y%m%d")
        merged_file_path = os.path.join(
            self.proxy_data_dir, 
            f"merged_proxies_valid_{today_date}.csv"
        )
        proxies_df.to_csv(merged_file_path, index=False, encoding="utf-8-sig")
        logging.info(f"ğŸ’¾ åˆå¹¶åçš„ä»£ç†æ•°æ®å·²ä¿å­˜åˆ°: {merged_file_path}")
        
        return proxies_df
        
    def get_latest_proxies(self) -> Optional[pd.DataFrame]:
        """
        è·å–æœ€æ–°çš„ä»£ç†æ•°æ®ï¼ˆä»å·²ä¿å­˜çš„æ–‡ä»¶ä¸­ï¼‰
        
        Returns:
            pd.DataFrame: æœ€æ–°çš„ä»£ç†æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        # æŸ¥æ‰¾æœ€æ–°çš„åˆå¹¶æ–‡ä»¶
        try:
            files = [f for f in os.listdir(self.proxy_data_dir) if f.startswith("merged_proxies_valid_") and f.endswith(".csv")]
            if not files:
                logging.warning("æœªæ‰¾åˆ°åˆå¹¶åçš„ä»£ç†æ–‡ä»¶")
                return None
                
            # æŒ‰æ–‡ä»¶åæ’åºï¼Œè·å–æœ€æ–°çš„
            files.sort(reverse=True)
            latest_file = files[0]
            file_path = os.path.join(self.proxy_data_dir, latest_file)
            
            df = pd.read_csv(file_path)
            logging.info(f"ğŸ“ ä» {latest_file} åŠ è½½äº† {len(df)} ä¸ªä»£ç†")
            return df
        except Exception as e:
            logging.error(f"åŠ è½½æœ€æ–°ä»£ç†æ•°æ®å¤±è´¥: {e}")
            return None

def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•ä»£ç†ç®¡ç†å™¨"""
    # åˆ›å»ºä»£ç†ç®¡ç†å™¨
    manager = ProxyManager("./proxy_data")
    
    # è·å–ä»£ç†
    proxies = manager.get_proxies(max_workers=10, verify_timeout=5.0, fallback=True)
    
    if not proxies.empty:
        print(f"âœ… æˆåŠŸè·å–åˆ° {len(proxies)} ä¸ªæœ‰æ•ˆä»£ç†:")
        print(proxies.head())
    else:
        print("âŒ æœªèƒ½è·å–åˆ°ä»»ä½•æœ‰æ•ˆä»£ç†")
        
    # æ˜¾ç¤ºæœ€æ–°ä»£ç†æ•°æ®
    latest_proxies = manager.get_latest_proxies()
    if latest_proxies is not None:
        print(f"\nğŸ“ æœ€æ–°ä»£ç†æ•°æ®åŒ…å« {len(latest_proxies)} ä¸ªä»£ç†")

if __name__ == "__main__":
    main()