# data_process.py
import os
from datetime import datetime

import pandas
import pandas as pd
from sqlalchemy.sql.functions import current_time

from Investment.THS.AutoTrade.config.settings import trade_operations_log_file, OPERATION_HISTORY_FILE, \
    Account_holding_file, Strategy_holding_file, \
    Combination_holding_file, Strategy_portfolio_today_file, Combination_portfolio_today_file
from Investment.THS.AutoTrade.pages.page_common import CommonPage
from Investment.THS.AutoTrade.scripts.trade_logic import TradeLogic
from Investment.THS.AutoTrade.pages.account_info import AccountInfo
from Investment.THS.AutoTrade.utils.format_data import normalize_time
from Investment.THS.AutoTrade.utils.logger import setup_logger

logger = setup_logger(trade_operations_log_file)
common_page = CommonPage()
account_info = AccountInfo()
trader = TradeLogic()

_operation_history_cache = None
_operation_history_cache_time = None
def read_portfolio_or_operation_data(file_paths, sheet_name=None):
    """
    é€šç”¨å‡½æ•°ç”¨äºè¯»å–æŠ•èµ„ç»„åˆæˆ–æ“ä½œå†å²æ•°æ®ã€‚

    å‚æ•°:
        file_path (str): Excel æ–‡ä»¶è·¯å¾„ã€‚
        sheet_name (str, optional): è¦è¯»å–çš„å·¥ä½œè¡¨åç§°ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸã€‚

    è¿”å›:
        pd.DataFrame: åŒ…å« 'æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%' çš„ DataFrameã€‚
    """
    global _operation_history_cache, _operation_history_cache_time
    #æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°ç¼“å­˜ï¼Œè¶…è¿‡ä¸€åˆ†é’Ÿæˆ–å¼ºåˆ¶åˆ·æ–°
    current_time = datetime.now()
    if _operation_history_cache_time is None or (current_time - _operation_history_cache_time).total_seconds() > 60:
        _operation_history_cache = read_portfolio_or_operation_data(file_paths, sheet_name)
        _operation_history_cache_time = current_time


    today = normalize_time(datetime.now().strftime('%Y-%m-%d'))
    required_columns = ['åç§°','æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%', 'æ—¶é—´']
    all_dfs = []

    if sheet_name is None:
        sheet_name = today
    elif sheet_name == 'all':
        sheet_name = None  # ç”¨äºåç»­åˆ¤æ–­è¯»å–æ‰€æœ‰sheet

    for file_path in file_paths:
        if not os.path.exists(file_path):
            logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue

        try:
            with pd.ExcelFile(file_path, engine='openpyxl') as xls:
                sheets = xls.sheet_names

                if sheet_name is None:
                    # è¯»å–æ‰€æœ‰sheet
                    sheets_to_read = sheets
                else:
                    sheets_to_read = [sheet_name] if sheet_name in sheets else []

                for sn in sheets_to_read:
                    df = pd.read_excel(xls, sheet_name=sn)

                    # ç¡®ä¿å…³é”®åˆ—å­˜åœ¨å¹¶è¿›è¡Œç±»å‹è½¬æ¢
                    for col in required_columns:
                        if col not in df.columns:
                            df[col] = ''

                    df['åç§°'] = df['åç§°'].astype(str).str.strip()
                    df['æ ‡çš„åç§°'] = df['æ ‡çš„åç§°'].astype(str).str.strip()
                    df['æ“ä½œ'] = df['æ“ä½œ'].astype(str).str.strip()
                    df['æ–°æ¯”ä¾‹%'] = pd.to_numeric(df['æ–°æ¯”ä¾‹%'], errors='coerce').fillna(0.0).round(2)
                    # df['æ—¶é—´'] = pd.to_numeric(df['æ—¶é—´'], errors='coerce').fillna(0.0).round(2)

                    all_dfs.append(df[required_columns])
                    logger.info(f"âœ… è¯»å–æ•°æ®æˆåŠŸ: {file_path}, è¡¨: {sn}, å…± {len(df)} æ¡è®°å½•")

                if not sheets_to_read:
                    logger.warning(f"æœªæ‰¾åˆ°å¯è¯»å–çš„å·¥ä½œè¡¨: {file_path}")
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}", exc_info=True)

        #return pd.DataFrame(columns=['æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%'])
    if not all_dfs:
        all_dfs = [pd.DataFrame(columns=required_columns)]
        # print(all_dfs)
        return all_dfs

    # åˆå¹¶æ‰€æœ‰æ•°æ®å¹¶å»é‡
    combined_df = pd.concat(all_dfs, ignore_index=True)
    combined_df.drop_duplicates(subset=required_columns, inplace=True)

    return combined_df

def write_to_excel_append(df, filename, sheet_name=None, index=False):
    """
    é€šç”¨å‡½æ•°ï¼šå°†DataFrameè¿½åŠ å†™å…¥Excelæ–‡ä»¶çš„æŒ‡å®šå·¥ä½œè¡¨ã€‚

    å‚æ•°:
        df (pd.DataFrame): è¦å†™å…¥çš„æ•°æ®ã€‚
        filename (str): æ–‡ä»¶è·¯å¾„ã€‚
        sheet_name (str): å·¥ä½œè¡¨åç§°ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸã€‚
        index (bool): æ˜¯å¦å†™å…¥è¡Œç´¢å¼•ã€‚
    """
    today = normalize_time(datetime.now().strftime('%Y-%m-%d'))
    if sheet_name is None:
        sheet_name = today

    try:
        # ç»Ÿä¸€æ•°æ®ç±»å‹
        if 'æ–°æ¯”ä¾‹%' in df.columns:
            df['æ–°æ¯”ä¾‹%'] = pd.to_numeric(df['æ–°æ¯”ä¾‹%'], errors='coerce').fillna(0.0).round(2)
        if 'æœ€æ–°ä»·' in df.columns:
            df['æœ€æ–°ä»·'] = pd.to_numeric(df['æœ€æ–°ä»·'], errors='coerce').fillna(0.0).round(2)
        if 'ä»£ç ' in df.columns:
            df['ä»£ç '] = df['ä»£ç '].astype(str).str.zfill(6)

        # å¤„ç†å­—ç¬¦ä¸²åˆ—
        for col in ['åç§°', 'æ ‡çš„åç§°', 'æ“ä½œ']:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()

        # å¡«å……ç©ºå€¼
        df = df.fillna('')

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶å¹¶å†™å…¥
        if not os.path.exists(filename):
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=index)
            logger.info(f"âœ… åˆ›å»ºå¹¶å†™å…¥æ–‡ä»¶: {filename}, è¡¨: {sheet_name}")
            return

        # æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–ç°æœ‰æ•°æ®
        existing_data = {}
        with pd.ExcelFile(filename, engine='openpyxl') as xls:
            # è¯»å–æ‰€æœ‰ç°æœ‰å·¥ä½œè¡¨
            for sn in xls.sheet_names:
                existing_data[sn] = pd.read_excel(xls, sheet_name=sn)

        # å¦‚æœç›®æ ‡å·¥ä½œè¡¨å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
        if sheet_name in existing_data:
            combined_df = pd.concat([existing_data[sheet_name], df], ignore_index=True)
            # å»é™¤é‡å¤è¡Œï¼ˆåŸºäºæ‰€æœ‰åˆ—ï¼‰
            combined_df = combined_df.drop_duplicates(keep='last')
        else:
            combined_df = df

        # æ›´æ–°ç›®æ ‡å·¥ä½œè¡¨æ•°æ®
        existing_data[sheet_name] = combined_df

        # é‡æ–°æ’åºå·¥ä½œè¡¨ï¼Œç¡®ä¿æœ€æ–°å·¥ä½œè¡¨åœ¨æœ€å‰é¢
        ordered_sheets = [sheet_name]  # æœ€æ–°å·¥ä½œè¡¨æ”¾åœ¨ç¬¬ä¸€ä½
        for sn in existing_data.keys():
            if sn != sheet_name:
                ordered_sheets.append(sn)

        # æŒ‰ç…§æ–°é¡ºåºé‡æ–°ç»„ç»‡æ•°æ®
        reordered_data = {sn: existing_data[sn] for sn in ordered_sheets}

        # é‡æ–°å†™å…¥æ‰€æœ‰å·¥ä½œè¡¨
        with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:
            for sn, data in reordered_data.items():
                data.to_excel(writer, sheet_name=sn, index=index)

        logger.info(f"âœ… æˆåŠŸè¿½åŠ å†™å…¥æ–‡ä»¶: {filename}, è¡¨: {sheet_name}ï¼Œæ–°å¢{len(df)}æ¡è®°å½•")

    except Exception as e:
        logger.error(f"âŒ è¿½åŠ å†™å…¥æ–‡ä»¶ {filename} å¤±è´¥: {e}", exc_info=True)

def read_today_portfolio_record(file_path):
    today = normalize_time(datetime.now().strftime('%Y-%m-%d'))
    # print(f'è¯»å–è°ƒä»“è®°å½•æ–‡ä»¶æ—¥æœŸ{today}')
    if os.path.exists(file_path):
        try:
            with pd.ExcelFile(file_path, engine='openpyxl') as portfolio_record_xlsx:
                if today in portfolio_record_xlsx.sheet_names:
                    portfolio_record_history_df = pd.read_excel(portfolio_record_xlsx, sheet_name=today)

                    # æ˜¾å¼è½¬æ¢å…³é”®åˆ—çš„ç±»å‹
                    portfolio_record_history_df['ä»£ç '] = portfolio_record_history_df['ä»£ç '].astype(str).str.zfill(6)
                    # portfolio_record_history_df['æ–°æ¯”ä¾‹%'] = portfolio_record_history_df['æ–°æ¯”ä¾‹%'].astype(float).round(2)
                    # portfolio_record_history_df['æœ€æ–°ä»·'] = portfolio_record_history_df['æœ€æ–°ä»·'].astype(float).round(2)

                    # å»é‡å¤„ç†
                    portfolio_record_history_df.drop_duplicates(
                        subset=['æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%', 'æ—¶é—´'],
                        inplace=True
                    )
                    logger.info(f"è¯»å–å»é‡åçš„æ“ä½œå†å²æ–‡ä»¶å®Œæˆ, {len(portfolio_record_history_df)}æ¡ \n{portfolio_record_history_df}")
                else:
                    portfolio_record_history_df = pd.DataFrame(columns=[
                        "åç§°", "æ“ä½œ", "æ ‡çš„åç§°", "ä»£ç ", "æœ€æ–°ä»·", "æ–°æ¯”ä¾‹%", "å¸‚åœº", "æ—¶é—´"
                    ])
                    logger.warning(f"ä»Šæ—¥è¡¨ä¸å­˜åœ¨: {today}")
        except Exception as e:
            logger.error(f"è¯»å–æ“ä½œå†å²æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
            portfolio_record_history_df = pd.DataFrame(columns=[
                "åç§°", "æ“ä½œ", "æ ‡çš„åç§°", "ä»£ç ", "æœ€æ–°ä»·", "æ–°æ¯”ä¾‹%", "å¸‚åœº", "æ—¶é—´"
            ])
    else:
        portfolio_record_history_df = pd.DataFrame(columns=[
            "åç§°", "æ“ä½œ", "æ ‡çš„åç§°", "ä»£ç ", "æœ€æ–°ä»·", "æ–°æ¯”ä¾‹%", "å¸‚åœº", "æ—¶é—´"
        ])
        logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    # print(f"è¯»å–çš„æ•°æ®ç±»å‹: \n{portfolio_record_history_df.dtypes}")
    return portfolio_record_history_df


def read_operation_history(history_file, force_refresh=False):
    """
    è¯»å–å½“æ—¥æ“ä½œå†å²

    å‚æ•°:
        history_file (str): å†å²æ–‡ä»¶è·¯å¾„
        force_refresh (bool): æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    """
    global _operation_history_cache, _operation_history_cache_time

    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°ç¼“å­˜ï¼ˆè¶…è¿‡1åˆ†é’Ÿæˆ–å¼ºåˆ¶åˆ·æ–°ï¼‰
    current_time = datetime.now()
    if not force_refresh and _operation_history_cache is not None:
        if _operation_history_cache_time and (current_time - _operation_history_cache_time).seconds < 60:
            return _operation_history_cache

    today = datetime.now().strftime('%Y-%m-%d')
    # æ˜¨å¤©
    # today = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    # print(f'è¯»å–å†å²æ–‡ä»¶æ—¥æœŸï¼š{today}')
    if not os.path.exists(history_file):
        return pd.DataFrame(columns=['æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%'])

    try:
        with pd.ExcelFile(history_file, engine='openpyxl') as f:
            if today in f.sheet_names:
                history_df = pd.read_excel(f, sheet_name=today)
                history_df['æ ‡çš„åç§°'] = history_df['æ ‡çš„åç§°'].astype(str).str.strip()
                history_df['æ“ä½œ'] = history_df['æ“ä½œ'].astype(str).str.strip()
                history_df['æ–°æ¯”ä¾‹%'] = history_df['æ–°æ¯”ä¾‹%'].astype(float).round(2)
                # æ·»åŠ æ›´å®Œæ•´çš„å”¯ä¸€æ ‡è¯†
                history_df['_id'] = history_df.apply(
                    lambda x: f"{x['æ ‡çš„åç§°']}_{x['æ“ä½œ']}_{x['æ–°æ¯”ä¾‹%']}", axis=1)
                logger.info(f"âœ… è¯»å–æ“ä½œå†å²æˆåŠŸï¼Œå…± {len(history_df)} æ¡è®°å½•\n{history_df}")
                _operation_history_cache = history_df
                _operation_history_cache_time = current_time
                return history_df
    except Exception as e:
        logger.warning(f"è¯»å–æ“ä½œå†å²å¤±è´¥ï¼Œå¯èƒ½æ–‡ä»¶è¢«å ç”¨æˆ–æŸå: {e}")
    return pd.DataFrame(columns=['æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%'])


def safe_concat(history_df, new_df):
    """å®‰å…¨çš„DataFrameæ‹¼æ¥"""
    if history_df.empty:
        return new_df.copy()
    if new_df.empty:
        return history_df.copy()

    # æ˜¾å¼ç»Ÿä¸€åˆ—é¡ºåºå’Œç±»å‹
    all_columns = set(history_df.columns) | set(new_df.columns)
    for col in all_columns:
        if col not in history_df.columns:
            history_df[col] = ''
        if col not in new_df.columns:
            new_df[col] = ''

    # æ˜¾å¼è½¬æ¢ä¸ºå¯¹è±¡ç±»å‹
    history_df = history_df.astype(object)
    new_df = new_df.astype(object)

    return pd.concat([history_df, new_df], ignore_index=True, sort=False)

def save_to_operation_history_excel(df, filename, sheet_name, index=False):
    """è¿½åŠ ä¿å­˜DataFrameåˆ°Excelæ–‡ä»¶ï¼Œé»˜è®¤ä»Šå¤©çš„åœ¨ç¬¬ä¸€å¼ è¡¨"""
    today = normalize_time(datetime.now().strftime('%Y-%m-%d'))  # è·å–ä»Šå¤©çš„æ—¥æœŸ

    # ç»Ÿä¸€æ•°æ®ç±»å‹
    df['æ–°æ¯”ä¾‹%'] = df['æ–°æ¯”ä¾‹%'].astype(float).round(2)
    df['æœ€æ–°ä»·'] = df['æœ€æ–°ä»·'].astype(float).round(2)
    df['ä»£ç '] = df['ä»£ç '].astype(str).str.zfill(6)

    # ä¿å­˜åˆ° Excel
    try:
        # æ ‡å‡†åŒ–æ•°æ®ç±»å‹
        df = df.fillna('')
        df = df.infer_objects(copy=False)
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶å¹¶å°†æ•°æ®ä¿å­˜åˆ°ç¬¬ä¸€ä¸ª sheet
        if not os.path.exists(filename):
            # print(f"ä¿å­˜çš„df {df}")
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=today, index=index)
                #æ‰“å°æ•°æ®ç±»å‹
                # print(f"ä¿å­˜çš„æ•°æ®ç±»å‹: \n{df.dtypes}")
            logger.info(f"âœ… åˆ›å»ºå¹¶ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶: {filename}, è¡¨åç§°: {today} \n{df}")
            return

        # æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–ç°æœ‰æ•°æ®
        with pd.ExcelFile(filename, engine='openpyxl') as xls:
            history_sheets = xls.sheet_names
            history_df = pd.read_excel(xls, sheet_name=sheet_name) if sheet_name in history_sheets else pd.DataFrame()

        # å¦‚æœä»Šå¤©çš„æ•°æ®éœ€è¦ä¿å­˜åˆ°ç¬¬ä¸€ä¸ª sheet
        if sheet_name == today:
            # è¯»å–ç°æœ‰ç¬¬ä¸€ä¸ª sheet çš„æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if history_sheets and history_sheets[0] == today:
                history_df = pd.read_excel(filename, sheet_name=today)
                # è¯»å–çš„æ•°æ®ç±»å‹
                # print(f"ä¿å­˜æ—¶ï¼Œè¯»å–çš„æ•°æ®ç±»å‹: \n{history_df.dtypes}")
                combined_df = safe_concat(history_df, df)
                # æ˜¾å¼æ¸…ç†æ— æ•ˆå€¼
                combined_df = combined_df.replace(['nan', 'NaN', 'N/A', 'None', None], '').infer_objects(copy=False)

                # é‡æ–°æ’åºå¹¶è®¾ç½®ç´¢å¼•
                # combined_df = combined_df[expected_columns]

                combined_df.drop_duplicates(subset=['åç§°', 'æ“ä½œ', 'æ ‡çš„åç§°', 'ä»£ç ', 'æœ€æ–°ä»·', 'æ–°æ¯”ä¾‹%'], inplace=True)
            else:
                combined_df = df

            # ä¿å­˜åˆ°ç¬¬ä¸€ä¸ª sheet
            with pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
                combined_df.to_excel(writer, sheet_name=today, index=index)
                #æ‰“å°æ•°æ®ç±»å‹
                # print(f"ä¿å­˜çš„æ•°æ®ç±»å‹: \n{combined_df.dtypes}")

            # è¯»å–å¹¶ä¿å­˜å…¶ä»– sheet çš„æ•°æ®
            other_sheets_data = {}
            for sheet in history_sheets:
                if sheet != today:
                    other_sheets_data[sheet] = pd.read_excel(filename, sheet_name=sheet)

            with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:
                combined_df.to_excel(writer, sheet_name=today, index=index)
                for sheet, data in other_sheets_data.items():
                    data.to_excel(writer, sheet_name=sheet, index=index)

            logger.info(f"âœ… æˆåŠŸè¿½åŠ æ•°æ®åˆ°Excelæ–‡ä»¶çš„ç¬¬ä¸€ä¸ªsheet: {filename}, è¡¨åç§°: {today} \n{combined_df}")
        else:
            # å¯¹äºéä»Šå¤©çš„ sheetï¼Œç›´æ¥è¿½åŠ æˆ–æ›¿æ¢
            with pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=index)
            logger.info(f"âœ… æˆåŠŸè¿½åŠ æ•°æ®åˆ°Excelæ–‡ä»¶çš„æŒ‡å®šsheet: {filename}, è¡¨åç§°: {sheet_name} \n{df}")

    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)

def write_operation_history(df):
    """å°†æ“ä½œè®°å½•å†™å…¥Excelæ–‡ä»¶ï¼ŒæŒ‰æ—¥æœŸä½œä¸ºsheetåï¼Œå¹¶ç¡®ä¿ä»Šæ—¥sheetä½äºç¬¬ä¸€ä¸ª"""
    global _operation_history_cache

    today = datetime.now().strftime('%Y-%m-%d')
    filename = OPERATION_HISTORY_FILE

    try:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥å†™å…¥æ–°æ–‡ä»¶
        if not os.path.exists(filename):
            save_to_operation_history_excel(df, filename, sheet_name=today, index=False)
            logger.info(f"æˆåŠŸå†™å…¥æ“ä½œè®°å½•åˆ° {today} è¡¨ {filename}")
            # æ›´æ–°ç¼“å­˜
            _operation_history_cache = df
            return

        # âœ… å…ˆè¯»å–å·²æœ‰æ•°æ®
        with pd.ExcelFile(filename, engine='openpyxl') as xls:
            history_sheets = xls.sheet_names
            old_df = pd.read_excel(xls, sheet_name=today) if today in history_sheets else pd.DataFrame()

        # åˆå¹¶æ–°æ—§æ•°æ®å¹¶å»é‡
        combined_df = pd.concat([old_df, df], ignore_index=True)
        combined_df.drop_duplicates(subset=['æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%'], keep='last', inplace=True)

        # è¯»å–å…¶ä»– sheet çš„æ•°æ®
        other_sheets_data = {}
        with pd.ExcelFile(filename, engine='openpyxl') as xls:
            for sheet in xls.sheet_names:
                if sheet != today:
                    other_sheets_data[sheet] = pd.read_excel(xls, sheet_name=sheet)

        # é‡æ–°å†™å…¥æ‰€æœ‰ sheetï¼Œç¡®ä¿ today æ˜¯ç¬¬ä¸€ä¸ª
        with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:
            combined_df.to_excel(writer, sheet_name=today, index=False)
            for sheet, data in other_sheets_data.items():
                data.to_excel(writer, sheet_name=sheet, index=False)

        logger.info(f"âœ… æˆåŠŸå†™å…¥æ“ä½œè®°å½•åˆ° {today} è¡¨ {filename}")

        # æ›´æ–°ç¼“å­˜
        _operation_history_cache = combined_df

    except Exception as e:
        logger.error(f"âŒ å†™å…¥æ“ä½œè®°å½•å¤±è´¥: {e}")
        raise





# å¯¹æ¯”account_infoæ–‡ä»¶å’ŒStrategy_holdingä»¥åŠCombination_holdingæ–‡ä»¶,å¦‚æœaccount_infoé‡Œæœ‰å…¶ä»–ä¸¤ä¸ªæ–‡ä»¶é‡Œæ²¡æœ‰çš„è‚¡ç¥¨æ ‡çš„ï¼Œåˆ™å–å‡ºæ“ä½œï¼Œåä¹‹ä¹°å…¥ï¼ˆé™¤äº†å·¥å•†é“¶è¡Œï¼Œä¸­å›½ç”µä¿¡ï¼Œå¯è½¬å€ºETFï¼Œå›½å€ºè¯é‡‘å€ºETFï¼‰
def get_difference_holding():
    """
    å¯¹æ¯”è´¦æˆ·æŒä»“ä¸ç­–ç•¥/ç»„åˆæŒä»“æ•°æ®ï¼Œæ‰¾å‡ºå·®å¼‚ï¼š
        - éœ€è¦å–å‡ºï¼šåœ¨è´¦æˆ·ä¸­å­˜åœ¨ï¼Œä½†åœ¨ç­–ç•¥/ç»„åˆä¸­ä¸å­˜åœ¨ï¼›
        - éœ€è¦ä¹°å…¥ï¼šåœ¨ç­–ç•¥/ç»„åˆä¸­å­˜åœ¨ï¼Œä½†åœ¨è´¦æˆ·ä¸­ä¸å­˜åœ¨ï¼›
    """
    try:
        # è¯»å–æŒä»“æ•°æ®
        account_df = pd.read_excel(Account_holding_file, sheet_name="æŒä»“æ•°æ®")
        strategy_df = pd.read_excel(Strategy_holding_file)
        combination_df = pd.read_excel(Combination_holding_file)

        logger.info(f"è´¦æˆ·æŒä»“æ•°æ®:\n{account_df[['æ ‡çš„åç§°']]}\n")
        logger.info(f"ç­–ç•¥æŒä»“æ•°æ®:\n{strategy_df[['æ ‡çš„åç§°']]}\n")
        logger.info(f"ç»„åˆæŒä»“æ•°æ®:\n{combination_df[['æ ‡çš„åç§°']]}\n")

        # åˆå¹¶ç­–ç•¥å’Œç»„åˆä¸­çš„æ‰€æœ‰æ ‡çš„åç§°
        combined_holdings = pd.concat([
            strategy_df[['æ ‡çš„åç§°']],
            combination_df[['æ ‡çš„åç§°']]
        ]).drop_duplicates().reset_index(drop=True)

        # éœ€è¦æ’é™¤çš„æ ‡çš„åç§°
        excluded_holdings = ["å·¥å•†é“¶è¡Œ","ä¸­å›½ç”µä¿¡","å¯è½¬å€ºETF","å›½å€ºæ”¿é‡‘å€ºETF"]

        # 1.æ‰¾å‡ºéœ€è¦å–å‡ºçš„æ ‡çš„ï¼ˆåœ¨è´¦æˆ·ä¸­å­˜åœ¨ï¼Œä½†ä¸åœ¨ç­–ç•¥ / ç»„åˆä¸­ï¼Œä¸”ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼‰
        to_sell_candidates = account_df[~account_df['æ ‡çš„åç§°'].isin(combined_holdings['æ ‡çš„åç§°'])]
        to_sell = to_sell_candidates[~to_sell_candidates['æ ‡çš„åç§°'].isin(excluded_holdings)]

        if not to_sell.empty:
            logger.warning("âš ï¸ å‘ç°éœ€å–å‡ºçš„æ ‡çš„:")
            # print("éœ€å–å‡ºçš„æ ‡çš„:")
            print(to_sell[['æ ‡çš„åç§°', 'æŒä»“/å¯ç”¨']])
        else:
            logger.info("âœ… å½“å‰æ— éœ€å–å‡ºçš„æ ‡çš„")

        # 2. æ‰¾å‡ºéœ€è¦ä¹°å…¥çš„æ ‡çš„ï¼ˆåœ¨ç­–ç•¥/ç»„åˆä¸­å­˜åœ¨ï¼Œä½†ä¸åœ¨è´¦æˆ·ä¸­ï¼‰
        to_buy_candidates = combined_holdings[~combined_holdings['æ ‡çš„åç§°'].isin(account_df['æ ‡çš„åç§°'])]
        to_buy = to_buy_candidates
        if not to_buy.empty:
            logger.warning("âš ï¸ å‘ç°éœ€ä¹°å…¥çš„æ ‡çš„:")
            print("éœ€ä¹°å…¥çš„æ ‡çš„:")
            print(to_buy[['æ ‡çš„åç§°']])
        else:
            logger.info("âœ… å½“å‰æ— éœ€ä¹°å…¥çš„æ ‡çš„")

        # æ„å»ºå®Œæ•´å·®å¼‚æŠ¥å‘Š
        difference_report = {
            "to_sell": to_sell,
            "to_buy": to_buy
        }

        return difference_report

    except Exception as e:
        logger.error(f"å¤„ç†æŒä»“å·®å¼‚æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return {"error": str(e)}

def process_excel_files(ths_page, file_paths, operation_history_file, history_df=None):
    # å¼ºåˆ¶åˆ·æ–°æ“ä½œå†å²ç¼“å­˜
    history_df = read_operation_history(operation_history_file, force_refresh=True)

    for file_path in file_paths:
        logger.info(f"ğŸ”„ æ£€æµ‹åˆ°æ–‡ä»¶æ›´æ–°ï¼Œå³å°†å¤„ç†: {file_path}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”éç©º
        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
            logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º: {file_path}")
            continue

        try:
            # è¯»å–è¦å¤„ç†çš„æ–‡ä»¶
            df = read_today_portfolio_record(file_path)
            if df.empty:
                logger.warning(f"æ–‡ä»¶ {file_path} ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
                continue

            # é»˜è®¤è´¦æˆ·ï¼ˆé AIå¸‚åœºè¿½è¸ªç­–ç•¥ æ—¶ä½¿ç”¨ï¼‰
            default_account = "ä¸­æ³°è¯åˆ¸"

            for index, row in df.iterrows():
                strategy_name = row['åç§°'].strip()
                stock_name = row['æ ‡çš„åç§°'].strip()
                operation = row['æ“ä½œ'].strip()
                new_ratio = float(row['æ–°æ¯”ä¾‹%'])

                # æ ¹æ®ç­–ç•¥åˆ‡æ¢è´¦æˆ·
                if strategy_name == "AIå¸‚åœºè¿½è¸ªç­–ç•¥":
                    logger.info("æ£€æµ‹åˆ° AIå¸‚åœºè¿½è¸ªç­–ç•¥ï¼Œåˆ‡æ¢è´¦æˆ·ä¸º æ¨¡æ‹Ÿ")
                    common_page.change_account("æ¨¡æ‹Ÿç»ƒä¹ åŒº")
                elif strategy_name in ["æœ‰è‰²é‡‘å±",'é’¢é“','å»ºç­‘è¡Œä¸š']:
                    logger.info("æ£€æµ‹åˆ° GPTç­–ç•¥ï¼Œåˆ‡æ¢è´¦æˆ·ä¸º å·è´¢è¯åˆ¸")
                    common_page.change_account("å·è´¢è¯åˆ¸")
                elif strategy_name in ["GPTå®šæœŸç²¾é€‰","ä¸­å­—å¤´èµ„é‡‘æµå…¥æˆ˜æ³•", "ä½ä»·å°å¸‚å€¼è‚¡æˆ˜æ³•", "é«˜ç°é‡‘æ¯›åˆ©æˆ˜æ³•"]:
                    common_page.change_account("é•¿åŸè¯åˆ¸")
                else:
                    common_page.change_account(default_account)

                logger.info(f"ğŸ› ï¸ è¦å¤„ç†: {operation} {stock_name} æ¯”ä¾‹:{new_ratio}")

                # åˆ¤æ–­æ˜¯å¦å·²æ‰§è¡Œ - ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…
                exists = history_df[
                    (history_df['æ ‡çš„åç§°'] == stock_name) &
                    (history_df['æ“ä½œ'] == operation) &
                    (abs(history_df['æ–°æ¯”ä¾‹%'] - new_ratio) < 0.01)  # ä½¿ç”¨è¿‘ä¼¼ç›¸ç­‰æ¯”è¾ƒ
                ]

                if not exists.empty:
                    logger.info(f"âœ… å·²å¤„ç†è¿‡: {stock_name} {operation} {new_ratio}%")
                    continue

                logger.info(f"ğŸš€ å¼€å§‹äº¤æ˜“: {operation} {stock_name}")

                # ç‰¹æ®Šå¤„ç†ï¼šå½“æ–°æ¯”ä¾‹ä¸º0ä¸”æ“ä½œä¸ºå–å‡ºæ—¶ï¼Œå¼ºåˆ¶å…¨ä»“å–å‡º
                if operation == "å–å‡º" and new_ratio == 0.0:
                    logger.info(f"ğŸ¯ ç‰¹æ®Šå¤„ç†: æ–°æ¯”ä¾‹ä¸º0ï¼Œå°†å…¨ä»“å–å‡º {stock_name}")
                    # ç›´æ¥è°ƒç”¨äº¤æ˜“é€»è¾‘ï¼Œä¸ä¾èµ–è‡ªåŠ¨è®¡ç®—æ•°é‡
                    status, info = trader.operate_stock(operation, stock_name)
                else:
                    status, info = trader.operate_stock(operation, stock_name)

                # æ„é€ è®°å½•
                operate_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                record = pd.DataFrame([{
                    'æ ‡çš„åç§°': stock_name,
                    'æ“ä½œ': operation,
                    'æ–°æ¯”ä¾‹%': new_ratio,
                    'çŠ¶æ€': status,
                    'ä¿¡æ¯': info,
                    'æ—¶é—´': operate_time
                }])

                # å†™å…¥å†å²
                write_operation_history(record)
                logger.info(f"{operation} {stock_name} æµç¨‹ç»“æŸï¼Œæ“ä½œå·²è®°å½•")

                # æ›´æ–°æœ¬åœ°å†å²è®°å½•DataFrameï¼Œé¿å…åœ¨åŒä¸€æ‰¹æ¬¡å¤„ç†ä¸­é‡å¤æ“ä½œ
                history_df = pd.concat([history_df, record], ignore_index=True)

        except pandas.errors.EmptyDataError:
            logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}", exc_info=True)


        #     logger.info(f"ğŸ› ï¸ è¦å¤„ç†: {operation} {stock_name} æ¯”ä¾‹:{new_ratio}")
        #
        #     # åˆ¤æ–­æ˜¯å¦å·²æ‰§è¡Œ - ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…
        #     exists = history_df[
        #         (history_df['æ ‡çš„åç§°'] == stock_name) &
        #         (history_df['æ“ä½œ'] == operation) &
        #         (abs(history_df['æ–°æ¯”ä¾‹%'] - new_ratio) < 0.01)  # ä½¿ç”¨è¿‘ä¼¼ç›¸ç­‰æ¯”è¾ƒ
        #     ]
        #
        #     if not exists.empty:
        #         logger.info(f"âœ… å·²å¤„ç†è¿‡: {stock_name} {operation} {new_ratio}%")
        #         continue
        #
        #     logger.info(f"ğŸš€ å¼€å§‹äº¤æ˜“: {operation} {stock_name}")
        #     # update_holding_info_all()
        #     # logger.info("æ›´æ–°æŒä»“ä¿¡æ¯å®Œæˆ")
        #
        #     status, info = trader.operate_stock(operation, stock_name)
        #
        #     # æ„é€ è®°å½•
        #     operate_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        #     record = pd.DataFrame([{
        #         'æ ‡çš„åç§°': stock_name,
        #         'æ“ä½œ': operation,
        #         'æ–°æ¯”ä¾‹%': new_ratio,
        #         'çŠ¶æ€': status,
        #         'ä¿¡æ¯': info,
        #         'æ—¶é—´': operate_time
        #     }])
        #
        #     # å†™å…¥å†å²
        #     write_operation_history(record)
        #     logger.info(f"{operation} {stock_name} æµç¨‹ç»“æŸï¼Œæ“ä½œå·²è®°å½•")
        #
        #     # æ›´æ–°æœ¬åœ°å†å²è®°å½•DataFrameï¼Œé¿å…åœ¨åŒä¸€æ‰¹æ¬¡å¤„ç†ä¸­é‡å¤æ“ä½œ
        #     history_df = pd.concat([history_df, record], ignore_index=True)
        #
        # except pandas.errors.EmptyDataError:
        #     logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
    # except Exception as e:
    #     logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}", exc_info=True)

if __name__ == '__main__':
    # diff_result = get_difference_holding()
    #
    # if 'error' in diff_result:
    #     print("æŒä»“å·®å¼‚åˆ†æå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ã€‚")
    # else:
    #     if not diff_result['to_sell'].empty:
    #         print("ğŸ’¡ å‘ç°éœ€å–å‡ºçš„è‚¡ç¥¨ï¼š")
    #         print(diff_result['to_sell'][['æ ‡çš„åç§°', 'æŒä»“/å¯ç”¨']])
    #     if not diff_result['to_buy'].empty:
    #         print("ğŸ’¡ å‘ç°éœ€ä¹°å…¥çš„è‚¡ç¥¨ï¼š")
    #         print(diff_result['to_buy'][['æ ‡çš„åç§°']])

    # file_path = Strategy_portfolio_today_file
    # file_path = [Strategy_portfolio_today_file,Combination_portfolio_today_file]
    # file_path = [OPERATION_HISTORY_FILE,Strategy_portfolio_today_file,Combination_portfolio_today_file]
    # file_path = [Strategy_portfolio_today_file,Combination_portfolio_today_file]
    # for file in file_path:
    #     if os.path.exists(file):
    #         print(f"æ–‡ä»¶ {file} å­˜åœ¨")
    #     else:
    #         print(f"æ–‡ä»¶ {file} ä¸å­˜åœ¨")
    #     # read_today_portfolio_record(file)
    #     portfolio_data = read_portfolio_or_operation_data(file_path)
    #     print(portfolio_data)

    today = datetime.now().strftime('%Y-%m-%d')
    data = [{"åç§°": "ç­–ç•¥åç§°3", "æ“ä½œ": "æ“ä½œ1", "æ ‡çš„åç§°": "æ ‡çš„åç§°1", 'ä»£ç ': '201',"æ–°æ¯”ä¾‹%": "251",'å¸‚åœº':'sdf','æ—¶é—´':'12'}]
    data = pd.DataFrame(data)
    # file_path = ["test.xlsx"]
    file_path = r'D:\Xander\Inverstment\Investment\THS\AutoTrade\data\trade_operation_history.xlsx'
    # file_path = "test.xlsx"
    write_to_excel_append(data,file_path, sheet_name=today)
    # read =read_portfolio_or_operation_data(file_path, sheet_name=today)
    # print(f"è¯»å–ï¼š\n{read}")

        # operation_data = read_portfolio_or_operation_data(OPERATION_HISTORY_FILE, sheet_name=today)

    # file_paths = [
    #     Strategy_portfolio_today_file,Combination_portfolio_today_file
    # ]
    # # from auto_trade_on_ths import THSPage
    # import uiautomator2 as u2
    # d = u2.connect()
    # package_name = "com.hexin.plat.android"
    # d.app_start(package_name, wait=True)
    # logger.info(f"å¯åŠ¨AppæˆåŠŸ: {package_name}")
    # ths_page = THSPage(d)
    # process_excel_files(ths_page=ths_page, file_paths=file_paths, operation_history_file=OPERATION_HISTORY_FILE, holding_stock_file=None)