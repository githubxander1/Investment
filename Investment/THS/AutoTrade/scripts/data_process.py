# data_process2.py
import os
from datetime import datetime, timedelta
from pprint import pprint

import pandas
import pandas as pd

from Investment.AutoPublic.jrtt.jrtt import send_notification
from Investment.THS.AutoTrade.config.settings import trade_operations_log_file, OPERATION_HISTORY_FILE, \
    Account_holding_file, Strategy_holding_file, \
    Combination_holding_file, Strategy_portfolio_today_file, Combination_portfolio_today_file, Lhw_portfolio_today_file, \
    Robot_holding_file
from Investment.THS.AutoTrade.pages.page_common import CommonPage
from Investment.THS.AutoTrade.scripts.trade_logic import TradeLogic
from Investment.THS.AutoTrade.pages.account_info import AccountInfo
from Investment.THS.AutoTrade.utils.format_data import normalize_time
from Investment.THS.AutoTrade.utils.logger import setup_logger

logger = setup_logger(trade_operations_log_file)
common_page = CommonPage()
account_info = AccountInfo()
trader = TradeLogic()

_operation_history_cache = None
_operation_history_cache_time = None


def read_portfolio_or_operation_data(file_path, sheet_name=None):
    """
    é€šç”¨å‡½æ•°ç”¨äºè¯»å–æŠ•èµ„ç»„åˆæˆ–æ“ä½œå†å²æ•°æ®ã€‚

    å‚æ•°:
        file_path (str): Excel æ–‡ä»¶è·¯å¾„ã€‚
        sheet_name (str, optional): è¦è¯»å–çš„å·¥ä½œè¡¨åç§°ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸã€‚

    è¿”å›:
        pd.DataFrame: åŒ…å« 'æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%' çš„ DataFrameã€‚
    """
    global _operation_history_cache, _operation_history_cache_time
    #æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°ç¼“å­˜ï¼Œè¶…è¿‡ä¸€åˆ†é’Ÿæˆ–å¼ºåˆ¶åˆ·æ–°
    # current_time = datetime.now()
    # if _operation_history_cache_time is None or (current_time - _operation_history_cache_time).total_seconds() > 60:
    #     _operation_history_cache = read_portfolio_or_operation_data(file_path, sheet_name)
    #     _operation_history_cache_time = current_time


    today = normalize_time(datetime.now().strftime('%Y-%m-%d'))
    all_dfs = []

    if sheet_name is None:
        sheet_name = today
    elif sheet_name == 'all':
        sheet_name = None  # ç”¨äºåç»­åˆ¤æ–­è¯»å–æ‰€æœ‰sheet

    if not os.path.exists(file_path):
        logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return [pd.DataFrame()]

    try:
        with pd.ExcelFile(file_path, engine='openpyxl') as xls:
            sheets = xls.sheet_names

            if sheet_name is None:
                # è¯»å–æ‰€æœ‰sheet
                sheets_to_read = sheets
            else:
                sheets_to_read = [sheet_name] if sheet_name in sheets else []

            for sn in sheets_to_read:
                df = pd.read_excel(xls, sheet_name=sn)

                if df is not None:
                    all_dfs.append(df)
                    logger.info(f"âœ… è¯»å–æ•°æ®æˆåŠŸ: {file_path}, è¡¨: {sn}, å…± {len(df)} æ¡è®°å½•")

            if not sheets_to_read:
                logger.warning(f"æœªæ‰¾åˆ°å¯è¯»å–çš„å·¥ä½œè¡¨: {file_path}")
    except Exception as e:
        logger.error(f"âŒ è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}", exc_info=True)
        return [pd.DataFrame()]

    if not all_dfs:
        all_dfs = [pd.DataFrame()]

    # åˆå¹¶æ‰€æœ‰æ•°æ®å¹¶å»é‡
    combined_df = pd.concat(all_dfs, ignore_index=True)
    combined_df.drop_duplicates(inplace=True)

    return combined_df


def save_to_excel_append(df, filename, sheet_name=None, index=False):
    """
    é€šç”¨å‡½æ•°ï¼šå°†DataFrameè¿½åŠ å†™å…¥Excelæ–‡ä»¶çš„æŒ‡å®šå·¥ä½œè¡¨ã€‚

    å‚æ•°:
        df (pd.DataFrame): è¦å†™å…¥çš„æ•°æ®ã€‚
        filename (str): æ–‡ä»¶è·¯å¾„ã€‚
        sheet_name (str): å·¥ä½œè¡¨åç§°ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸã€‚
        index (bool): æ˜¯å¦å†™å…¥è¡Œç´¢å¼•ã€‚
    """
    today = normalize_time(datetime.now().strftime('%Y-%m-%d'))
    if sheet_name is None:
        sheet_name = today

    try:
        # ç»Ÿä¸€æ•°æ®ç±»å‹
        if 'æ–°æ¯”ä¾‹%' in df.columns:
            df['æ–°æ¯”ä¾‹%'] = pd.to_numeric(df['æ–°æ¯”ä¾‹%'], errors='coerce').fillna(0.0).round(2)
        if 'æœ€æ–°ä»·' in df.columns:
            df['æœ€æ–°ä»·'] = pd.to_numeric(df['æœ€æ–°ä»·'], errors='coerce').fillna(0.0).round(2)
        if 'ä»£ç ' in df.columns:
            df['ä»£ç '] = df['ä»£ç '].astype(str).str.zfill(6)

        # å¤„ç†å­—ç¬¦ä¸²åˆ—
        for col in ['åç§°', 'æ ‡çš„åç§°', 'æ“ä½œ']:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()

        # å¡«å……ç©ºå€¼
        df = df.fillna('')

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶å¹¶å†™å…¥
        if not os.path.exists(filename):
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=index)
            logger.info(f"âœ… åˆ›å»ºå¹¶å†™å…¥æ–‡ä»¶: {filename}, è¡¨: {sheet_name}")
            return

        # æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–ç°æœ‰æ•°æ®
        existing_data = {}
        try:
            with pd.ExcelFile(filename, engine='openpyxl') as xls:
                # è¯»å–æ‰€æœ‰ç°æœ‰å·¥ä½œè¡¨
                for sn in xls.sheet_names:
                    existing_data[sn] = pd.read_excel(xls, sheet_name=sn)
        except Exception as e:
            logger.warning(f"è¯»å–ç°æœ‰æ–‡ä»¶æ—¶å‡ºç°é—®é¢˜: {e}ï¼Œå°†è¦†ç›–æ–‡ä»¶")
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=index)
            logger.info(f"âœ… é‡æ–°åˆ›å»ºå¹¶å†™å…¥æ–‡ä»¶: {filename}, è¡¨: {sheet_name}")
            return

        # å¦‚æœç›®æ ‡å·¥ä½œè¡¨å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
        if sheet_name in existing_data:
            try:
                combined_df = pd.concat([existing_data[sheet_name], df], ignore_index=True)
                # å»é™¤é‡å¤è¡Œï¼ˆåŸºäºæ‰€æœ‰åˆ—ï¼‰
                combined_df = combined_df.drop_duplicates(keep='last')
            except Exception as e:
                logger.warning(f"åˆå¹¶æ•°æ®æ—¶å‡ºç°é—®é¢˜: {e}ï¼Œä½¿ç”¨æ–°æ•°æ®")
                combined_df = df
        else:
            combined_df = df

        # æ›´æ–°ç›®æ ‡å·¥ä½œè¡¨æ•°æ®
        existing_data[sheet_name] = combined_df

        # é‡æ–°æ’åºå·¥ä½œè¡¨ï¼Œç¡®ä¿æœ€æ–°å·¥ä½œè¡¨åœ¨æœ€å‰é¢
        ordered_sheets = [sheet_name]  # æœ€æ–°å·¥ä½œè¡¨æ”¾åœ¨ç¬¬ä¸€ä½
        for sn in sorted(existing_data.keys(), reverse=True):  # æŒ‰å­—æ¯å€’åºæ’åˆ—å…¶ä»–è¡¨
            if sn != sheet_name:
                ordered_sheets.append(sn)

        # æŒ‰ç…§æ–°é¡ºåºé‡æ–°ç»„ç»‡æ•°æ®
        reordered_data = {sn: existing_data[sn] for sn in ordered_sheets}

        # é‡æ–°å†™å…¥æ‰€æœ‰å·¥ä½œè¡¨
        with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:
            for sn, data in reordered_data.items():
                # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®åå†å†™å…¥
                if 'ä»£ç ' in data.columns:
                    data['ä»£ç '] = data['ä»£ç '].astype(str).str.zfill(6)
                if 'æ–°æ¯”ä¾‹%' in data.columns:
                    data['æ–°æ¯”ä¾‹%'] = pd.to_numeric(data['æ–°æ¯”ä¾‹%'], errors='coerce').fillna(0.0).round(2)
                if 'æœ€æ–°ä»·' in data.columns:
                    data['æœ€æ–°ä»·'] = pd.to_numeric(data['æœ€æ–°ä»·'], errors='coerce').fillna(0.0).round(2)

                # å¤„ç†å­—ç¬¦ä¸²åˆ—
                for col in ['åç§°', 'æ ‡çš„åç§°', 'æ“ä½œ']:
                    if col in data.columns:
                        data[col] = data[col].astype(str).str.strip()

                data.to_excel(writer, sheet_name=sn, index=index)

        logger.info(f"âœ… æˆåŠŸè¿½åŠ å†™å…¥æ–‡ä»¶: {filename}, è¡¨: {sheet_name}ï¼Œæ–°å¢{len(df)}æ¡è®°å½•")

    except PermissionError:
        logger.error(f"âŒ æ–‡ä»¶è¢«å ç”¨ï¼Œæ— æ³•å†™å…¥: {filename}ï¼Œè¯·å…³é—­æ–‡ä»¶åé‡è¯•")
    except Exception as e:
        logger.error(f"âŒ è¿½åŠ å†™å…¥æ–‡ä»¶ {filename} å¤±è´¥: {e}", exc_info=True)


def read_today_portfolio_record(file_path):
    today = normalize_time(datetime.now().strftime('%Y-%m-%d'))
    # print(f'è¯»å–è°ƒä»“è®°å½•æ–‡ä»¶æ—¥æœŸ{today}')
    if os.path.exists(file_path):
        try:
            with pd.ExcelFile(file_path, engine='openpyxl') as portfolio_record_xlsx:
                if today in portfolio_record_xlsx.sheet_names:
                    portfolio_record_history_df = pd.read_excel(portfolio_record_xlsx, sheet_name=today)

                    # å»é‡å¤„ç†
                    portfolio_record_history_df.drop_duplicates(
                        subset=['æ ‡çš„åç§°', 'æ“ä½œ', "æ–°æ¯”ä¾‹%", 'æ—¶é—´'],
                        inplace=True
                    )
                    logger.info(f"è¯»å–å»é‡åçš„æ“ä½œå†å²æ–‡ä»¶å®Œæˆ, {len(portfolio_record_history_df)}æ¡ \n{portfolio_record_history_df}")
                else:
                    portfolio_record_history_df = pd.DataFrame(columns=[
                        "åç§°", "æ“ä½œ", "æ ‡çš„åç§°", "ä»£ç ", "æœ€æ–°ä»·", "æ–°æ¯”ä¾‹%", "å¸‚åœº", "æ—¶é—´"
                    ])
                    logger.warning(f"ä»Šæ—¥è¡¨ä¸å­˜åœ¨: {today}")
        except Exception as e:
            logger.error(f"è¯»å–æ“ä½œå†å²æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
            portfolio_record_history_df = pd.DataFrame(columns=[
                "åç§°", "æ“ä½œ", "æ ‡çš„åç§°", "ä»£ç ", "æœ€æ–°ä»·", "æ–°æ¯”ä¾‹%", "å¸‚åœº", "æ—¶é—´"
            ])
    else:
        portfolio_record_history_df = pd.DataFrame(columns=[
            "åç§°", "æ“ä½œ", "æ ‡çš„åç§°", "ä»£ç ", "æœ€æ–°ä»·", "æ–°æ¯”ä¾‹%", "å¸‚åœº", "æ—¶é—´"
        ])
        logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    # print(f"è¯»å–çš„æ•°æ®ç±»å‹: \n{portfolio_record_history_df.dtypes}")
    return portfolio_record_history_df


def read_operation_history(history_file, force_refresh=False):
    """
    è¯»å–å½“æ—¥æ“ä½œå†å²

    å‚æ•°:
        history_file (str): å†å²æ–‡ä»¶è·¯å¾„
        force_refresh (bool): æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    """
    global _operation_history_cache, _operation_history_cache_time

    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°ç¼“å­˜ï¼ˆè¶…è¿‡1åˆ†é’Ÿæˆ–å¼ºåˆ¶åˆ·æ–°ï¼‰
    current_time = datetime.now()
    if not force_refresh and _operation_history_cache is not None:
        if _operation_history_cache_time and (current_time - _operation_history_cache_time).seconds < 60:
            return _operation_history_cache

    today = datetime.now().strftime('%Y-%m-%d')
    # æ˜¨å¤©
    # today = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    # print(f'è¯»å–å†å²æ–‡ä»¶æ—¥æœŸï¼š{today}')
    if not os.path.exists(history_file):
        return pd.DataFrame(columns=['æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%'])

    try:
        with pd.ExcelFile(history_file, engine='openpyxl') as f:
            if today in f.sheet_names:
                history_df = pd.read_excel(f, sheet_name=today)
                history_df['æ ‡çš„åç§°'] = history_df['æ ‡çš„åç§°'].astype(str).str.strip()
                history_df['æ“ä½œ'] = history_df['æ“ä½œ'].astype(str).str.strip()
                history_df['æ–°æ¯”ä¾‹%'] = history_df['æ–°æ¯”ä¾‹%'].astype(float).round(2)
                # æ·»åŠ æ›´å®Œæ•´çš„å”¯ä¸€æ ‡è¯†
                history_df['_id'] = history_df.apply(
                    lambda x: f"{x['æ ‡çš„åç§°']}_{x['æ“ä½œ']}_{x['æ–°æ¯”ä¾‹%']}", axis=1)
                logger.info(f"âœ… è¯»å–æ“ä½œå†å²æˆåŠŸï¼Œå…± {len(history_df)} æ¡è®°å½•\n{history_df}")
                _operation_history_cache = history_df
                _operation_history_cache_time = current_time
                return history_df
    except Exception as e:
        logger.warning(f"è¯»å–æ“ä½œå†å²å¤±è´¥ï¼Œå¯èƒ½æ–‡ä»¶è¢«å ç”¨æˆ–æŸå: {e}")
    return pd.DataFrame(columns=['æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%'])


def safe_concat(history_df, new_df):
    """å®‰å…¨çš„DataFrameæ‹¼æ¥"""
    if history_df.empty:
        return new_df.copy()
    if new_df.empty:
        return history_df.copy()

    # æ˜¾å¼ç»Ÿä¸€åˆ—é¡ºåºå’Œç±»å‹
    all_columns = set(history_df.columns) | set(new_df.columns)
    for col in all_columns:
        if col not in history_df.columns:
            history_df[col] = ''
        if col not in new_df.columns:
            new_df[col] = ''

    # æ˜¾å¼è½¬æ¢ä¸ºå¯¹è±¡ç±»å‹
    history_df = history_df.astype(object)
    new_df = new_df.astype(object)

    return pd.concat([history_df, new_df], ignore_index=True, sort=False)


def save_to_operation_history_excel(df, filename, sheet_name, index=False):
    """è¿½åŠ ä¿å­˜DataFrameåˆ°Excelæ–‡ä»¶ï¼Œé»˜è®¤ä»Šå¤©çš„åœ¨ç¬¬ä¸€å¼ è¡¨"""
    today = normalize_time(datetime.now().strftime('%Y-%m-%d'))  # è·å–ä»Šå¤©çš„æ—¥æœŸ

    # ç»Ÿä¸€æ•°æ®ç±»å‹
    df['æ–°æ¯”ä¾‹%'] = df['æ–°æ¯”ä¾‹%'].astype(float).round(2)
    df['æœ€æ–°ä»·'] = df['æœ€æ–°ä»·'].astype(float).round(2)
    df['ä»£ç '] = df['ä»£ç '].astype(str).str.zfill(6)

    # ä¿å­˜åˆ° Excel
    try:
        # æ ‡å‡†åŒ–æ•°æ®ç±»å‹
        df = df.fillna('')
        df = df.infer_objects(copy=False)
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶å¹¶å°†æ•°æ®ä¿å­˜åˆ°ç¬¬ä¸€ä¸ª sheet
        if not os.path.exists(filename):
            # print(f"ä¿å­˜çš„df {df}")
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=today, index=index)
                #æ‰“å°æ•°æ®ç±»å‹
                # print(f"ä¿å­˜çš„æ•°æ®ç±»å‹: \n{df.dtypes}")
            logger.info(f"âœ… åˆ›å»ºå¹¶ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶: {filename}, è¡¨åç§°: {today} \n{df}")
            return

        # æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–ç°æœ‰æ•°æ®
        with pd.ExcelFile(filename, engine='openpyxl') as xls:
            history_sheets = xls.sheet_names
            history_df = pd.read_excel(xls, sheet_name=sheet_name) if sheet_name in history_sheets else pd.DataFrame()

        # å¦‚æœä»Šå¤©çš„æ•°æ®éœ€è¦ä¿å­˜åˆ°ç¬¬ä¸€ä¸ª sheet
        if sheet_name == today:
            # è¯»å–ç°æœ‰ç¬¬ä¸€ä¸ª sheet çš„æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if history_sheets and history_sheets[0] == today:
                history_df = pd.read_excel(filename, sheet_name=today)
                # è¯»å–çš„æ•°æ®ç±»å‹
                # print(f"ä¿å­˜æ—¶ï¼Œè¯»å–çš„æ•°æ®ç±»å‹: \n{history_df.dtypes}")
                combined_df = safe_concat(history_df, df)
                # æ˜¾å¼æ¸…ç†æ— æ•ˆå€¼
                combined_df = combined_df.replace(['nan', 'NaN', 'N/A', 'None', None], '').infer_objects(copy=False)

                # é‡æ–°æ’åºå¹¶è®¾ç½®ç´¢å¼•
                # combined_df = combined_df[expected_columns]

                combined_df.drop_duplicates(subset=['åç§°', 'æ“ä½œ', 'æ ‡çš„åç§°', 'ä»£ç ', 'æœ€æ–°ä»·', 'æ–°æ¯”ä¾‹%'], inplace=True)
            else:
                combined_df = df

            # ä¿å­˜åˆ°ç¬¬ä¸€ä¸ª sheet
            with pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
                combined_df.to_excel(writer, sheet_name=today, index=index)
                #æ‰“å°æ•°æ®ç±»å‹
                # print(f"ä¿å­˜çš„æ•°æ®ç±»å‹: \n{combined_df.dtypes}")

            # è¯»å–å¹¶ä¿å­˜å…¶ä»– sheet çš„æ•°æ®
            other_sheets_data = {}
            for sheet in history_sheets:
                if sheet != today:
                    other_sheets_data[sheet] = pd.read_excel(filename, sheet_name=sheet)

            with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:
                combined_df.to_excel(writer, sheet_name=today, index=index)
                for sheet, data in other_sheets_data.items():
                    data.to_excel(writer, sheet_name=sheet, index=index)

            logger.info(f"âœ… æˆåŠŸè¿½åŠ æ•°æ®åˆ°Excelæ–‡ä»¶çš„ç¬¬ä¸€ä¸ªsheet: {filename}, è¡¨åç§°: {today} \n{combined_df}")
        else:
            # å¯¹äºéä»Šå¤©çš„ sheetï¼Œç›´æ¥è¿½åŠ æˆ–æ›¿æ¢
            with pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=index)
            logger.info(f"âœ… æˆåŠŸè¿½åŠ æ•°æ®åˆ°Excelæ–‡ä»¶çš„æŒ‡å®šsheet: {filename}, è¡¨åç§°: {sheet_name} \n{df}")

    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)


def write_operation_history(df):
    """å°†æ“ä½œè®°å½•å†™å…¥Excelæ–‡ä»¶ï¼ŒæŒ‰æ—¥æœŸä½œä¸ºsheetåï¼Œå¹¶ç¡®ä¿ä»Šæ—¥sheetä½äºç¬¬ä¸€ä¸ª"""
    global _operation_history_cache

    today = datetime.now().strftime('%Y-%m-%d')
    filename = OPERATION_HISTORY_FILE

    try:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶å¹¶å°†æ•°æ®ä¿å­˜åˆ°ç¬¬ä¸€ä¸ª sheet
        if not os.path.exists(filename):
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=today, index=False)
            logger.info(f"âœ… åˆ›å»ºå¹¶ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶: {filename}, è¡¨åç§°: {today} \n{df}")
            # æ›´æ–°ç¼“å­˜
            _operation_history_cache = df
            return

        # âœ… å…ˆè¯»å–ä»Šå¤©çš„sheetå·²æœ‰æ•°æ®
        with pd.ExcelFile(filename, engine='openpyxl') as xls:
            history_sheets = xls.sheet_names
            old_df = pd.read_excel(xls, sheet_name=today) if today in history_sheets else pd.DataFrame()

        # åˆå¹¶æ–°æ—§æ•°æ®å¹¶å»é‡
        combined_df = pd.concat([old_df, df], ignore_index=True)
        combined_df.drop_duplicates(subset=['æ ‡çš„åç§°', 'æ“ä½œ', 'æ–°æ¯”ä¾‹%'], keep='last', inplace=True)

        # è¯»å–å…¶ä»– sheet çš„æ•°æ®
        other_sheets_data = {}
        with pd.ExcelFile(filename, engine='openpyxl') as xls:
            for sheet in xls.sheet_names:
                if sheet != today:
                    other_sheets_data[sheet] = pd.read_excel(xls, sheet_name=sheet)

        # é‡æ–°å†™å…¥æ‰€æœ‰ sheetï¼Œç¡®ä¿ today æ˜¯ç¬¬ä¸€ä¸ª
        with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:
            combined_df.to_excel(writer, sheet_name=today, index=False)
            for sheet, data in other_sheets_data.items():
                data.to_excel(writer, sheet_name=sheet, index=False)

        logger.info(f"âœ… æˆåŠŸå†™å…¥æ“ä½œè®°å½•åˆ° {today} è¡¨ {filename}")

        # æ›´æ–°ç¼“å­˜
        _operation_history_cache = combined_df

    except Exception as e:
        error_info = f"âŒ å†™å…¥æ“ä½œè®°å½•å¤±è´¥: {e}"
        logger.error(error_info)
        send_notification(error_info)
        raise


def get_difference_holding():
    """
    å¯¹æ¯”è´¦æˆ·æŒä»“ä¸ç­–ç•¥/ç»„åˆæŒä»“æ•°æ®ï¼Œæ‰¾å‡ºå·®å¼‚ï¼š
        - éœ€è¦å–å‡ºï¼šåœ¨è´¦æˆ·ä¸­å­˜åœ¨ï¼Œä½†ä¸åœ¨ç­–ç•¥/ç»„åˆä¸­ï¼›
        - éœ€è¦ä¹°å…¥ï¼šåœ¨ç­–ç•¥/ç»„åˆä¸­å­˜åœ¨ï¼Œä½†ä¸åœ¨è´¦æˆ·ä¸­ï¼›
    """
    try:
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = {
            "è´¦æˆ·æŒä»“æ–‡ä»¶": Account_holding_file,
            "ç­–ç•¥æŒä»“æ–‡ä»¶": Strategy_holding_file,
            "ç»„åˆæŒä»“æ–‡ä»¶": Combination_holding_file,
            "RobotæŒä»“æ–‡ä»¶": Robot_holding_file
        }

        for file_desc, file_path in required_files.items():
            if not os.path.exists(file_path):
                logger.error(f"{file_desc}ä¸å­˜åœ¨: {file_path}")
                return {"error": f"{file_desc}ä¸å­˜åœ¨"}

        # è¯»å–è´¦æˆ·æŒä»“æ•°æ®ï¼ˆä»æ‰€æœ‰è´¦æˆ·çš„æŒä»“æ•°æ®è¡¨ä¸­è¯»å–ï¼‰
        account_dfs = []
        try:
            with pd.ExcelFile(Account_holding_file, engine='openpyxl') as xls:
                account_sheets = xls.sheet_names

                for sheet in account_sheets:
                    if sheet.endswith('_æŒä»“æ•°æ®'):  # åªè¯»å–æŒä»“æ•°æ®è¡¨
                        try:
                            df = pd.read_excel(xls, sheet_name=sheet)
                            if not df.empty and 'æ ‡çš„åç§°' in df.columns:
                                # åªä¿ç•™æ ‡çš„åç§°åˆ—ï¼Œå¹¶æ·»åŠ è´¦æˆ·æ ‡è¯†
                                df_filtered = df[['æ ‡çš„åç§°']].copy()
                                df_filtered['è´¦æˆ·'] = sheet.replace('_æŒä»“æ•°æ®', '')
                                account_dfs.append(df_filtered)
                                logger.info(f"âœ… æˆåŠŸè¯»å–è´¦æˆ· {sheet} çš„æŒä»“æ•°æ®ï¼Œå…± {len(df_filtered)} æ¡è®°å½•")
                        except Exception as e:
                            logger.warning(f"è¯»å–è´¦æˆ·å·¥ä½œè¡¨ {sheet} å¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"è¯»å–è´¦æˆ·æŒä»“æ–‡ä»¶å¤±è´¥: {e}")
            return {"error": "è¯»å–è´¦æˆ·æŒä»“æ–‡ä»¶å¤±è´¥"}

        if not account_dfs:
            logger.error("æ— æ³•ä»è´¦æˆ·æ–‡ä»¶ä¸­è¯»å–æœ‰æ•ˆçš„æŒä»“æ•°æ®")
            return {"error": "æ— æ³•è¯»å–è´¦æˆ·æŒä»“æ•°æ®"}

        # åˆå¹¶æ‰€æœ‰è´¦æˆ·çš„æŒä»“æ•°æ®
        account_df = pd.concat(account_dfs, ignore_index=True).drop_duplicates(subset=['æ ‡çš„åç§°'])
        logger.info(f"åˆå¹¶åè´¦æˆ·æŒä»“æ•°æ®å…± {len(account_df)} æ¡è®°å½•")

        # è¯»å–ç­–ç•¥æŒä»“æ•°æ®
        try:
            if os.path.exists(Strategy_holding_file) and os.path.getsize(Strategy_holding_file) > 0:
                strategy_df = pd.read_excel(Strategy_holding_file)
                if strategy_df.empty:
                    logger.warning("ç­–ç•¥æŒä»“æ–‡ä»¶ä¸ºç©º")
                    strategy_df = pd.DataFrame(columns=['æ ‡çš„åç§°'])
            else:
                logger.warning("ç­–ç•¥æŒä»“æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                strategy_df = pd.DataFrame(columns=['æ ‡çš„åç§°'])
        except Exception as e:
            logger.error(f"è¯»å–ç­–ç•¥æŒä»“æ–‡ä»¶å¤±è´¥: {e}")
            strategy_df = pd.DataFrame(columns=['æ ‡çš„åç§°'])

        # è¯»å–ç»„åˆæŒä»“æ•°æ®
        try:
            if os.path.exists(Combination_holding_file) and os.path.getsize(Combination_holding_file) > 0:
                combination_df = pd.read_excel(Combination_holding_file)
                if combination_df.empty:
                    logger.warning("ç»„åˆæŒä»“æ–‡ä»¶ä¸ºç©º")
                    combination_df = pd.DataFrame(columns=['æ ‡çš„åç§°'])
            else:
                logger.warning("ç»„åˆæŒä»“æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                combination_df = pd.DataFrame(columns=['æ ‡çš„åç§°'])
        except Exception as e:
            logger.error(f"è¯»å–ç»„åˆæŒä»“æ–‡ä»¶å¤±è´¥: {e}")
            combination_df = pd.DataFrame(columns=['æ ‡çš„åç§°'])

        logger.info(f"è´¦æˆ·æŒä»“æ•°æ®:\n{account_df[['æ ‡çš„åç§°']]}\n")
        if not strategy_df.empty:
            logger.info(f"ç­–ç•¥æŒä»“æ•°æ®:\n{strategy_df[['æ ‡çš„åç§°']]}\n")
        if not combination_df.empty:
            logger.info(f"ç»„åˆæŒä»“æ•°æ®:\n{combination_df[['æ ‡çš„åç§°']]}\n")

        # åˆå¹¶ç­–ç•¥å’Œç»„åˆä¸­çš„æ‰€æœ‰æ ‡çš„åç§°
        combined_dfs = []
        if not strategy_df.empty and 'æ ‡çš„åç§°' in strategy_df.columns:
            combined_dfs.append(strategy_df[['æ ‡çš„åç§°']])
        if not combination_df.empty and 'æ ‡çš„åç§°' in combination_df.columns:
            combined_dfs.append(combination_df[['æ ‡çš„åç§°']])

        if combined_dfs:
            combined_holdings = pd.concat(combined_dfs, ignore_index=True).drop_duplicates(subset=['æ ‡çš„åç§°']).reset_index(drop=True)
        else:
            combined_holdings = pd.DataFrame(columns=['æ ‡çš„åç§°'])

        logger.info(f"ç­–ç•¥å’Œç»„åˆåˆå¹¶åæŒä»“æ•°æ®å…± {len(combined_holdings)} æ¡è®°å½•")

        # éœ€è¦æ’é™¤çš„æ ‡çš„åç§°
        excluded_holdings = ["å·¥å•†é“¶è¡Œ", "ä¸­å›½ç”µä¿¡", "å¯è½¬å€ºETF", "å›½å€ºæ”¿é‡‘å€ºETF"]

        # 1. æ‰¾å‡ºéœ€è¦å–å‡ºçš„æ ‡çš„ï¼ˆåœ¨è´¦æˆ·ä¸­å­˜åœ¨ï¼Œä½†ä¸åœ¨ç­–ç•¥/ç»„åˆä¸­ï¼Œä¸”ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼‰
        if not account_df.empty and not combined_holdings.empty:
            to_sell_candidates = account_df[~account_df['æ ‡çš„åç§°'].isin(combined_holdings['æ ‡çš„åç§°'])]
            to_sell = to_sell_candidates[~to_sell_candidates['æ ‡çš„åç§°'].isin(excluded_holdings)].copy()  # æ·»åŠ  .copy()
        else:
            to_sell = pd.DataFrame(columns=account_df.columns) if not account_df.empty else pd.DataFrame()

        if not to_sell.empty:
            logger.warning("âš ï¸ å‘ç°éœ€å–å‡ºçš„æ ‡çš„:")
            logger.info(f"\n{to_sell[['æ ‡çš„åç§°']] if 'æ ‡çš„åç§°' in to_sell.columns else to_sell}")
        else:
            logger.info("âœ… å½“å‰æ— éœ€å–å‡ºçš„æ ‡çš„")

        # 2. æ‰¾å‡ºéœ€è¦ä¹°å…¥çš„æ ‡çš„ï¼ˆåœ¨ç­–ç•¥/ç»„åˆä¸­å­˜åœ¨ï¼Œä½†ä¸åœ¨è´¦æˆ·ä¸­ï¼Œä¸”ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼‰
        if not combined_holdings.empty and not account_df.empty:
            to_buy_candidates = combined_holdings[~combined_holdings['æ ‡çš„åç§°'].isin(account_df['æ ‡çš„åç§°'])]
            to_buy = to_buy_candidates[~to_buy_candidates['æ ‡çš„åç§°'].isin(excluded_holdings)]
        elif not combined_holdings.empty:
            # å¦‚æœè´¦æˆ·æŒä»“ä¸ºç©ºï¼Œåˆ™æ‰€æœ‰ç­–ç•¥/ç»„åˆæŒä»“éƒ½æ˜¯éœ€è¦ä¹°å…¥çš„ï¼ˆé™¤å»æ’é™¤é¡¹ï¼‰
            to_buy = combined_holdings[~combined_holdings['æ ‡çš„åç§°'].isin(excluded_holdings)]
        else:
            to_buy = pd.DataFrame(columns=['æ ‡çš„åç§°'])

        if not to_buy.empty:
            logger.warning("âš ï¸ å‘ç°éœ€ä¹°å…¥çš„æ ‡çš„:")
            logger.info(f"\n{to_buy[['æ ‡çš„åç§°']] if 'æ ‡çš„åç§°' in to_buy.columns else to_buy}")
        else:
            logger.info("âœ… å½“å‰æ— éœ€ä¹°å…¥çš„æ ‡çš„")

        # æ„å»ºå®Œæ•´å·®å¼‚æŠ¥å‘Š
        difference_report = {
            "to_sell": to_sell,
            "to_buy": to_buy
        }

        return difference_report

    except Exception as e:
        error_msg = f"å¤„ç†æŒä»“å·®å¼‚æ—¶å‘ç”Ÿé”™è¯¯: {e}"
        logger.error(error_msg, exc_info=True)
        return {"error": error_msg}

def get_stock_to_operate(trade_history_file, today_portfolio_file):
    # é»˜è®¤è´¦æˆ·ï¼ˆé AIå¸‚åœºè¿½è¸ªç­–ç•¥ æ—¶ä½¿ç”¨ï¼‰
    # default_account = "ä¸­æ³°è¯åˆ¸"  # ç»„åˆ
    today_portfolio_df = read_portfolio_or_operation_data(today_portfolio_file,today)
    print(f"[è°ƒè¯•] è·å–ä»Šæ—¥æŒä»“æ•°æ®: {today_portfolio_df}")
    trade_history_df = read_portfolio_or_operation_data(trade_history_file,today)
    print(f"[è°ƒè¯•] è·å–äº¤æ˜“è®°å½•æ•°æ®: {trade_history_df}")

    to_operate_list = []
    for index, row in today_portfolio_df.iterrows():
        strategy_name = row['åç§°'].strip()
        stock_name = row['æ ‡çš„åç§°'].strip()
        operation = row['æ“ä½œ'].strip()
        new_ratio = float(row['æ–°æ¯”ä¾‹%'])

        # åˆ¤æ–­æ˜¯å¦å·²æ‰§è¡Œ - ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…
        exists = trade_history_df[
            (trade_history_df['æ ‡çš„åç§°'] == stock_name) &
            (trade_history_df['æ“ä½œ'] == operation) &
            (abs(trade_history_df['æ–°æ¯”ä¾‹%'] - new_ratio) < 0.01)  # ä½¿ç”¨è¿‘ä¼¼ç›¸ç­‰æ¯”è¾ƒ
            ]

        if not exists.empty:
            logger.info(f"âœ… å·²å¤„ç†è¿‡: {stock_name} {operation} {new_ratio}%")
            continue
        to_operate_list.append(exists)

def extract_operations_to_perform_for_portfolio_file(file_paths):
    """
    æå–æ‰€æœ‰éœ€è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¸å®é™…æ‰§è¡Œäº¤æ˜“
    é€‚ç”¨äº: portfolio_todayå’Œtrade_historyæ–‡ä»¶

    è¿”å›:
        dict: æŒ‰è´¦æˆ·åˆ†ç»„çš„æ“ä½œåˆ—è¡¨
        {
            "å·è´¢è¯åˆ¸": [
                {"strategy_name": "...", "stock_name": "...", "operation": "...", "new_ratio": ..., ...},
                ...
            ],
            "é•¿åŸè¯åˆ¸": [...],
            "ä¸­æ³°è¯åˆ¸": [...]
        }
    """
    # å¼ºåˆ¶åˆ·æ–°æ“ä½œå†å²ç¼“å­˜
    operation_history_file = OPERATION_HISTORY_FILE
    history_df = read_operation_history(operation_history_file, force_refresh=True)

    # åˆ›å»ºå·²å¤„ç†è®°å½•çš„ç´¢å¼•é›†åˆï¼Œæé«˜æŸ¥æ‰¾æ•ˆç‡
    processed_operations = set()
    for _, row in history_df.iterrows():
        key = (row['æ ‡çš„åç§°'], row['æ“ä½œ'], round(row['æ–°æ¯”ä¾‹%'], 2))
        processed_operations.add(key)

    # æŒ‰è´¦æˆ·åˆ†ç»„çš„æ“ä½œå­—å…¸
    operations_by_account = {
        "å·è´¢è¯åˆ¸": [],
        "é•¿åŸè¯åˆ¸": [],
        "ä¸­æ³°è¯åˆ¸": []
    }

    for file_path in file_paths:
        logger.info(f"ğŸ”„ æ£€æµ‹åˆ°æ–‡ä»¶æ›´æ–°ï¼Œå³å°†å¤„ç†: {file_path}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”éç©º
        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
            logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º: {file_path}")
            continue

        try:
            # è¯»å–è¦å¤„ç†çš„æ–‡ä»¶
            today_portfolio_df = read_today_portfolio_record(file_path)
            if today_portfolio_df.empty:
                logger.warning(f"æ–‡ä»¶ {file_path} ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
                continue

            # éå†æ‰€æœ‰æ“ä½œ
            for index, row in today_portfolio_df.iterrows():
                strategy_name = row['åç§°'].strip()
                stock_name = row['æ ‡çš„åç§°'].strip()
                operation = row['æ“ä½œ'].strip()
                new_ratio = float(row['æ–°æ¯”ä¾‹%'])
                price = float(row['æœ€æ–°ä»·'])

                logger.info(f"ğŸ› ï¸ è¦å¤„ç†: {operation} {stock_name} {price} æ¯”ä¾‹:{new_ratio}")

                # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
                operation_key = (stock_name, operation, round(new_ratio, 2))
                if operation_key in processed_operations:
                    logger.info(f"âœ… å·²å¤„ç†è¿‡: {stock_name} {operation} {price} æ¯”ä¾‹:{new_ratio}%")
                    continue

                # ç¡®å®šè´¦æˆ·ç±»å‹
                if strategy_name in ["AIå¸‚åœºè¿½è¸ªç­–ç•¥", "GPTå®šæœŸç²¾é€‰"]:  # ç­–ç•¥
                    account = "å·è´¢è¯åˆ¸"
                elif strategy_name in ["æœ‰è‰²é‡‘å±", 'é’¢é“', 'å»ºç­‘è¡Œä¸š']:  # æœºå™¨äºº
                    account = "é•¿åŸè¯åˆ¸"
                else:  # ç»„åˆ
                    account = "ä¸­æ³°è¯åˆ¸"

                # æ·»åŠ åˆ°å¯¹åº”è´¦æˆ·çš„æ“ä½œåˆ—è¡¨ä¸­
                operations_by_account[account].append({
                    "strategy_name": strategy_name,
                    "stock_name": stock_name,
                    "operation": operation,
                    "price": price,
                    "new_ratio": new_ratio,
                    "file_path": file_path  # ç”¨äºæ—¥å¿—è®°å½•
                })

                # logger.info(f"ğŸ“ è®°å½•æ“ä½œ: {account} - {operation} {stock_name} {price} æ¯”ä¾‹:{new_ratio}")

        except pandas.errors.EmptyDataError:
            logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}", exc_info=True)

    # è¿‡æ»¤æ‰ç©ºçš„è´¦æˆ·åˆ—è¡¨
    operations_by_account = {k: v for k, v in operations_by_account.items() if v}
    operations_by_account_df = pandas.DataFrame(operations_by_account)

    if not operations_by_account:
        logger.info("âœ… æ²¡æœ‰éœ€è¦æ‰§è¡Œçš„æ“ä½œ")
    else:
        for account, operations in operations_by_account.items():
            logger.info(f"ğŸ“‹ è´¦æˆ· {account} éœ€è¦æ‰§è¡Œ {len(operations)} ä¸ªæ“ä½œ\n{operations_by_account_df}")

    return operations_by_account


def process_data_to_operate(file_paths):
    """
    å¤„ç†Excelæ–‡ä»¶ä¸­çš„äº¤æ˜“æŒ‡ä»¤ï¼ŒæŒ‰è´¦æˆ·åˆ†ç»„å¤„ç†ä»¥å‡å°‘è´¦æˆ·åˆ‡æ¢æ¬¡æ•°
    """
    # æå–æ‰€æœ‰éœ€è¦æ‰§è¡Œçš„æ“ä½œ
    operations_by_account = extract_operations_to_perform_for_portfolio_file(file_paths)

    if not operations_by_account:
        return

    # æ±‡æ€»æ‰€æœ‰æ“ä½œç»“æœç”¨äºæœ€ç»ˆé€šçŸ¥
    all_operations_result = []

    # æŒ‰è´¦æˆ·é¡ºåºå¤„ç†
    for account, operations in operations_by_account.items():
        if not operations:
            continue

        logger.info(f"ğŸ“‹ å¼€å§‹å¤„ç†è´¦æˆ· {account} çš„ {len(operations)} ä¸ªæ“ä½œ")
        # åˆ‡æ¢åˆ°å¯¹åº”è´¦æˆ·
        common_page.change_account(account)
        logger.info(f"âœ… å·²åˆ‡æ¢åˆ°è´¦æˆ·: {account}")

        # æ‰§è¡Œè¯¥è´¦æˆ·ä¸‹çš„æ‰€æœ‰æ“ä½œ
        for op in operations:
            strategy_name = op["strategy_name"]
            stock_name = op["stock_name"]
            operation = op["operation"]
            new_ratio = op["new_ratio"]

            logger.info(f"ğŸš€ å¼€å§‹äº¤æ˜“: {operation} {stock_name}")

            # åˆå§‹åŒ–çŠ¶æ€å’Œä¿¡æ¯
            status = None
            info = "æœªçŸ¥é”™è¯¯"

            try:
                # ç‰¹æ®Šå¤„ç†ï¼šå½“æ–°æ¯”ä¾‹ä¸º0ä¸”æ“ä½œä¸ºå–å‡ºæ—¶ï¼Œå¼ºåˆ¶å…¨ä»“å–å‡º
                if operation == "å–å‡º" and new_ratio == 0:
                    logger.info(f"ğŸ¯ ç‰¹æ®Šå¤„ç†: æ–°æ¯”ä¾‹ä¸º0ï¼Œå°†å…¨ä»“å–å‡º {stock_name}")
                    # ç›´æ¥è°ƒç”¨äº¤æ˜“é€»è¾‘ï¼Œä¸ä¾èµ–è‡ªåŠ¨è®¡ç®—æ•°é‡
                    status, info = trader.operate_stock(operation, stock_name, volume=None, new_ratio=new_ratio)

                # ç‰¹æ®Šå¤„ç†ï¼šAIå¸‚åœºè¿½è¸ªç­–ç•¥ä¹°å…¥æ—¶ä½¿ç”¨å›ºå®šè‚¡æ•°
                elif strategy_name == "AIå¸‚åœºè¿½è¸ªç­–ç•¥" and operation == "ä¹°å…¥":
                    fixed_volume = 200  # å›ºå®šä¹°å…¥200è‚¡
                    logger.info(f"ğŸ¯ AIå¸‚åœºè¿½è¸ªç­–ç•¥ç‰¹æ®Šå¤„ç†: ä¹°å…¥ {stock_name} å›ºå®šæ•°é‡ {fixed_volume} è‚¡")
                    status, info = trader.operate_stock(operation, stock_name, volume=fixed_volume)
                else:
                    status, info = trader.operate_stock(operation, stock_name, volume=None, new_ratio=new_ratio)

                # æ£€æŸ¥äº¤æ˜“æ˜¯å¦æˆåŠŸæ‰§è¡Œ
                if status is None:
                    logger.error(f"âŒ {operation} {stock_name} äº¤æ˜“æ‰§è¡Œå¤±è´¥: {info}")
                    all_operations_result.append(f"{account}: {operation} {stock_name} å¤±è´¥ - {info}")
                else:
                    logger.info(f"âœ… {operation} {stock_name} äº¤æ˜“æ‰§è¡ŒæˆåŠŸ: {info}")
                    all_operations_result.append(f"{account}: {operation} {stock_name} æˆåŠŸ - {info}")

            except Exception as e:
                logger.error(f"å¤„ç† {operation} {stock_name} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
                info = str(e)
                all_operations_result.append(f"{account}: {operation} {stock_name} å¼‚å¸¸ - {info}")

            # æ„é€ è®°å½•
            operate_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            record = pd.DataFrame([{
                'æ ‡çš„åç§°': stock_name,
                'æ“ä½œ': operation,
                'æ–°æ¯”ä¾‹%': new_ratio,
                'çŠ¶æ€': status,
                'ä¿¡æ¯': info,
                'æ—¶é—´': operate_time
            }])

            # å†™å…¥å†å²
            write_operation_history(record)
            logger.info(f"{operation} {stock_name} æµç¨‹ç»“æŸï¼Œæ“ä½œå·²è®°å½•")

            # æ›´æ–°æœ¬åœ°å†å²è®°å½•DataFrameï¼Œé¿å…åœ¨åŒä¸€æ‰¹æ¬¡å¤„ç†ä¸­é‡å¤æ“ä½œ
            # history_df = pd.concat([history_df, record], ignore_index=True)

        # except Exception as e:
        #     logger.error(f"å¤„ç† {operation} {stock_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)


    logger.info("âœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ")

    # å‘é€æ“ä½œç»“æœé€šçŸ¥
    if all_operations_result:
        summary_message = "äº¤æ˜“æ“ä½œç»“æœæ±‡æ€»:\n" + "\n".join(all_operations_result)
        from Investment.THS.AutoTrade.utils.notification import send_notification
        send_notification(summary_message)

if __name__ == '__main__':
    # diff_result = get_difference_holding()
    #
    # if 'error' in diff_result:
    #     print("æŒä»“å·®å¼‚åˆ†æå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ã€‚")
    # else:
    #     if not diff_result['to_sell'].empty:
    #         print("ğŸ’¡ å‘ç°éœ€å–å‡ºçš„è‚¡ç¥¨ï¼š")
    #         # æ˜¾ç¤ºéœ€è¦å–å‡ºçš„è‚¡ç¥¨åŠå…¶è´¦æˆ·ä¿¡æ¯
    #         if 'è´¦æˆ·' in diff_result['to_sell'].columns:
    #             print(diff_result['to_sell'][['æ ‡çš„åç§°', 'è´¦æˆ·']])
    #         else:
    #             print(diff_result['to_sell'][['æ ‡çš„åç§°']])
    #     else:
    #         print("âœ… å½“å‰æ— éœ€å–å‡ºçš„æ ‡çš„")
    #
    #     if not diff_result['to_buy'].empty:
    #         print("ğŸ’¡ å‘ç°éœ€ä¹°å…¥çš„è‚¡ç¥¨ï¼š")
    #         print(diff_result['to_buy'][['æ ‡çš„åç§°']])
    #     else:
    #         print("âœ… å½“å‰æ— éœ€ä¹°å…¥çš„æ ‡çš„")

    # file_path = Strategy_portfolio_today_file
    # file_path = [Strategy_portfolio_today_file,Combination_portfolio_today_file]
    # file_path = [OPERATION_HISTORY_FILE,Strategy_portfolio_today_file,Combination_portfolio_today_file]
    # file_path = [Strategy_portfolio_today_file,Combination_portfolio_today_file]
    # for file in file_path:
    #     if os.path.exists(file):
    #         print(f"æ–‡ä»¶ {file} å­˜åœ¨")
    #     else:
    #         print(f"æ–‡ä»¶ {file} ä¸å­˜åœ¨")
    #     # read_today_portfolio_record(file)
    #     portfolio_data = read_portfolio_or_operation_data(file_path)
    #     print(portfolio_data)

    today = datetime.now().strftime('%Y-%m-%d')
    # æ˜¨å¤©
    today = (datetime.now() - timedelta(days=4)).strftime('%Y-%m-%d')
    portfolio_file_path = r'/Investment/THS/AutoTrade/data/portfolio/Robot_portfolio_today.xlsx'
    read = read_portfolio_or_operation_data(portfolio_file_path, sheet_name=today)
    print(f"è¯»å–ï¼š\n{read}")

    file_paths = [
        # Strategy_holding_file,
        Combination_portfolio_today_file,
        Lhw_portfolio_today_file
    ]
    df = extract_operations_to_perform_for_portfolio_file(file_paths)
    pprint(df)
    # print(get_stock_to_operate(trade_history_file_path,portfolio_file_path))

        # operation_data = read_portfolio_or_operation_data(OPERATION_HISTORY_FILE, sheet_name=today)

    # file_paths = [
    #     Lhw_portfolio_today_file
    # ]
    # # from auto_trade_on_ths import THSPage
    # import uiautomator2 as u2
    # d = u2.connect()
    # package_name = "com.hexin.plat.android"
    # d.app_start(package_name, wait=True)
    # logger.info(f"å¯åŠ¨AppæˆåŠŸ: {package_name}")
    # # ths_page = THSPage(d)
    # process_data_to_operate(file_paths=file_paths, operation_history_file=OPERATION_HISTORY_FILE)